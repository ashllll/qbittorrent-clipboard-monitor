"""
å¢å¼ºçš„qBittorrentå®¢æˆ·ç«¯æ¨¡å—

æ”¯æŒï¼š
- æ™ºèƒ½é‡è¯•æœºåˆ¶
- å¢å¼ºçš„é”™è¯¯å¤„ç†
- å¤šè§„åˆ™è·¯å¾„æ˜ å°„
- æ›´å¤šAPIåŠŸèƒ½
"""

import asyncio
import json
import logging
import urllib.parse
import time
import hashlib
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor
from typing import Dict, List, Optional, Tuple, Any
import aiohttp
from tenacity import (
    retry, 
    stop_after_attempt, 
    wait_exponential,
    retry_if_exception_type,
    before_sleep_log
)

from .config import QBittorrentConfig, CategoryConfig, PathMappingRule, AppConfig
from .resilience import RateLimiter, CircuitBreaker, LRUCache, MetricsTracker
from .exceptions import (
    QBittorrentError, NetworkError, QbtAuthError, 
    QbtRateLimitError, QbtPermissionError, TorrentParseError
)
from .utils import parse_magnet


class QBittorrentClient:
    """å¢å¼ºçš„å¼‚æ­¥qBittorrent APIå®¢æˆ·ç«¯ï¼Œå…·æœ‰æ™ºèƒ½é‡è¯•æœºåˆ¶ã€å¢å¼ºé”™è¯¯å¤„ç†ã€å¤šè§„åˆ™è·¯å¾„æ˜ å°„å’Œæ›´å¤šAPIåŠŸèƒ½"""
    
    def __init__(self, config: QBittorrentConfig, app_config: Optional[AppConfig] = None):
        self.config = config
        self.app_config = app_config
        self.session: Optional[aiohttp.ClientSession] = None
        self.logger = logging.getLogger('QBittorrentClient')
        self._base_url = f"{'https' if config.use_https else 'http'}://{config.host}:{config.port}"
        self._authenticated = False
        
        # è¿æ¥æ± é…ç½®
        self._connection_pool_size = getattr(config, 'connection_pool_size', 10)
        self._sessions: List[aiohttp.ClientSession] = []
        self._session_index = 0
        self._session_lock = asyncio.Lock()
        
        # æ¸…ç†çŠ¶æ€æ ‡å¿—
        self._is_cleaned_up = False
        self._cleanup_lock = asyncio.Lock()
        
        # ç¼“å­˜ç³»ç»Ÿ
        self._cache_ttl = getattr(config, 'cache_ttl_seconds', 300)
        self._cache = LRUCache(
            max_size=getattr(config, 'cache_max_size', 1000),
            ttl_seconds=self._cache_ttl,
        )
        
        # æ€§èƒ½ç›‘æ§
        self._metrics = MetricsTracker()
        
        # æ–­è·¯å™¨
        self._circuit_breaker = CircuitBreaker(
            failure_threshold=getattr(config, 'circuit_breaker_threshold', 5),
            recovery_timeout=getattr(config, 'circuit_breaker_timeout', 60),
            on_state_change=self._on_circuit_state_change,
        )
        
        # é€Ÿç‡é™åˆ¶
        self._max_requests_per_minute = getattr(config, 'max_requests_per_minute', 60)
        self._rate_limiter = RateLimiter(self._max_requests_per_minute)
        
        # çº¿ç¨‹æ± ç”¨äºå¼‚æ­¥æ“ä½œ
        self._executor = ThreadPoolExecutor(max_workers=4)
    
    async def close(self):
        """å…³é—­æ‰€æœ‰ä¼šè¯ï¼ˆä¿æŒå‘åå…¼å®¹ï¼‰"""
        await self.cleanup()
    
    async def cleanup(self):
        """æ¸…ç†æ‰€æœ‰èµ„æº"""
        self.logger.info("ğŸ” [è¯Šæ–­] QBittorrentClient.cleanup() è¢«è°ƒç”¨")
        async with self._cleanup_lock:
            if self._is_cleaned_up:
                self.logger.info("ğŸ” [è¯Šæ–­] èµ„æºå·²æ ‡è®°ä¸ºæ¸…ç†ï¼Œä½†æ£€æŸ¥å®é™…çŠ¶æ€...")
                self.logger.info(f"ğŸ” [è¯Šæ–­] è¿æ¥æ± çŠ¶æ€: {len(self._sessions)} ä¸ªä¼šè¯")
                # å³ä½¿æ ‡è®°ä¸ºå·²æ¸…ç†ï¼Œä¹Ÿè¦æ£€æŸ¥æ˜¯å¦è¿˜æœ‰æœªå…³é—­çš„ä¼šè¯
                unclosed_count = 0
                for session in self._sessions:
                    if session and not session.closed:
                        unclosed_count += 1
                if unclosed_count > 0:
                    self.logger.warning(f"âš ï¸ [è¯Šæ–­] å‘ç° {unclosed_count} ä¸ªæœªå…³é—­ä¼šè¯ï¼Œå¼ºåˆ¶æ¸…ç†")
                    self._is_cleaned_up = False  # é‡ç½®æ ‡å¿—ï¼Œå¼ºåˆ¶æ¸…ç†
                else:
                    self.logger.info("âœ… [è¯Šæ–­] ç¡®è®¤æ‰€æœ‰ä¼šè¯å·²å…³é—­ï¼Œè·³è¿‡æ¸…ç†")
                    return
            
            self.logger.info("å¼€å§‹æ¸…ç†QBittorrentClientèµ„æº...")
            
            try:
                # å…³é—­æ‰€æœ‰HTTPä¼šè¯ï¼Œè®©aiohttpè‡ªåŠ¨ç®¡ç†connector
                async with self._session_lock:
                    self.logger.info(f"ğŸ” [è¯Šæ–­] æ¸…ç†å‰æ£€æŸ¥: è¿æ¥æ± ä¸­æœ‰ {len(self._sessions)} ä¸ªä¼šè¯")
                    
                    for i, session in enumerate(self._sessions):
                        if session and not session.closed:
                            self.logger.info(f"ğŸ”§ [è¯Šæ–­] æ­£åœ¨å…³é—­ä¼šè¯ {i+1}/{len(self._sessions)}")
                            await session.close()
                        else:
                            self.logger.warning(f"âš ï¸ [è¯Šæ–­] ä¼šè¯ {i+1} å·²å…³é—­æˆ–ä¸ºNone")
                    self._sessions.clear()
                    
                    if self.session and not self.session.closed:
                        self.logger.info("ğŸ”§ [è¯Šæ–­] å…³é—­ä¸»ä¼šè¯")
                        await self.session.close()
                    
                    # ç­‰å¾…å¼‚æ­¥å…³é—­æ“ä½œå®Œæˆ
                    self.logger.info("â³ [è¯Šæ–­] ç­‰å¾…ä¼šè¯å®Œå…¨å…³é—­...")
                    await asyncio.sleep(0.5)
                    
                    self.logger.info("âœ… [è¯Šæ–­] æ‰€æœ‰HTTPä¼šè¯å·²å…³é—­")
                
                # æ¸…ç†ç¼“å­˜
                if hasattr(self, '_cache'):
                    self._cache.clear()
                    self.logger.debug("ç¼“å­˜å·²æ¸…ç†")
                
                # å…³é—­çº¿ç¨‹æ± 
                if hasattr(self, '_executor') and self._executor:
                    self._executor.shutdown(wait=True)
                    self.logger.debug("çº¿ç¨‹æ± å·²å…³é—­")
                
                self._is_cleaned_up = True
                self.logger.info("QBittorrentClientèµ„æºæ¸…ç†å®Œæˆ")
                
            except Exception as e:
                self.logger.error(f"æ¸…ç†QBittorrentClientèµ„æºæ—¶å‡ºé”™: {str(e)}")
    
    def __del__(self):
        """ææ„å‡½æ•°ï¼Œç¡®ä¿èµ„æºè¢«æ¸…ç†"""
        if not self._is_cleaned_up:
            try:
                # åŒæ­¥æ¸…ç†å…³é”®èµ„æº
                if hasattr(self, '_cache'):
                    self._cache.clear()
                    
                if hasattr(self, '_executor') and self._executor:
                    self._executor.shutdown(wait=False)
                
                # å¼ºåˆ¶å…³é—­æ‰€æœ‰ä¼šè¯ï¼ˆåŒæ­¥æ–¹å¼ï¼‰
                if hasattr(self, '_sessions'):
                    for session in self._sessions:
                        if session and not session.closed:
                            try:
                                # ä½¿ç”¨åŒæ­¥æ–¹å¼å¼ºåˆ¶å…³é—­
                                if hasattr(session, '_connector') and session._connector:
                                    session._connector.close()
                            except Exception:
                                pass
                    self._sessions.clear()
                
                if hasattr(self, 'session') and self.session and not self.session.closed:
                    try:
                        if hasattr(self.session, '_connector') and self.session._connector:
                            self.session._connector.close()
                    except Exception:
                        pass
                    
            except Exception:
                pass  # å¿½ç•¥ææ„æ—¶çš„å¼‚å¸¸
        
    async def __aenter__(self):
        # åˆå§‹åŒ–è¿æ¥æ± 
        timeout = aiohttp.ClientTimeout(total=30, connect=10)
        
        # åˆ›å»ºè¿æ¥æ± ä¸­çš„ä¼šè¯ï¼Œæ¯ä¸ªä¼šè¯ä½¿ç”¨ç‹¬ç«‹çš„connector
        for i in range(self._connection_pool_size):
            connector = aiohttp.TCPConnector(
                limit=100, 
                limit_per_host=30,
                keepalive_timeout=30,
                enable_cleanup_closed=True
            )
            session = aiohttp.ClientSession(
                timeout=timeout,
                connector=connector
            )
            self._sessions.append(session)
        
        # è®¾ç½®ä¸»ä¼šè¯ä¸ºç¬¬ä¸€ä¸ª
        self.session = self._sessions[0] if self._sessions else None
        
        await self.login()
        return self
    
    async def __aexit__(self, exc_type, exc, tb):
        """å¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨é€€å‡º"""
        await self.cleanup()
    
    async def _get_next_session(self) -> aiohttp.ClientSession:
        """è·å–è¿æ¥æ± ä¸­çš„ä¸‹ä¸€ä¸ªä¼šè¯"""
        async with self._session_lock:
            if not self._sessions:
                return self.session
            
            session = self._sessions[self._session_index]
            self._session_index = (self._session_index + 1) % len(self._sessions)
            return session
    
    def _get_cache_key(self, method: str, url: str, params: dict = None, data: dict = None) -> str:
        """ç”Ÿæˆç¼“å­˜é”®"""
        key_data = f"{method}:{url}"
        if params:
            key_data += f":params:{sorted(params.items())}"
        if data:
            key_data += f":data:{sorted(data.items())}"
        return hashlib.md5(key_data.encode()).hexdigest()
    
    def _get_from_cache(self, cache_key: str) -> Optional[Any]:
        """ä»ç¼“å­˜è·å–æ•°æ®"""
        cached = self._cache.get(cache_key)
        if cached is not None:
            self._metrics.inc('cache_hits')
            return cached
        self._metrics.inc('cache_misses')
        return None
    
    def _put_to_cache(self, cache_key: str, data: Any):
        """å°†æ•°æ®æ”¾å…¥ç¼“å­˜"""
        self._cache.set(cache_key, data)
    
    def _check_rate_limit(self) -> bool:
        """æ£€æŸ¥é€Ÿç‡é™åˆ¶"""
        return self._rate_limiter.allow()
    
    def _check_circuit_breaker(self) -> bool:
        """æ£€æŸ¥æ–­è·¯å™¨çŠ¶æ€"""
        return self._circuit_breaker.allow()
    
    def _record_success(self):
        """è®°å½•æˆåŠŸè¯·æ±‚"""
        self._circuit_breaker.record_success()
    
    def _record_failure(self):
        """è®°å½•å¤±è´¥è¯·æ±‚"""
        self._circuit_breaker.record_failure()
    
    def _on_circuit_state_change(self, state: str):
        if state == 'open':
            self.logger.warning("æ–­è·¯å™¨å·²æ‰“å¼€ï¼Œæš‚åœæ–°çš„è¯·æ±‚")
        elif state == 'half_open':
            self.logger.info("æ–­è·¯å™¨è¿›å…¥åŠå¼€çŠ¶æ€ï¼Œå°è¯•æ¢å¤è¿æ¥")
        elif state == 'closed':
            self.logger.info("æ–­è·¯å™¨æ¢å¤åˆ°å…³é—­çŠ¶æ€")
    
    def get_performance_stats(self) -> Dict[str, Any]:
        """è·å–æ€§èƒ½ç»Ÿè®¡ä¿¡æ¯"""
        snapshot = self._metrics.snapshot()
        cache_total = max(1, snapshot['cache_hits'] + snapshot['cache_misses'])
        total_requests = max(1, snapshot['requests'])
        return {
            'total_requests': snapshot['requests'],
            'cache_hit_rate': (snapshot['cache_hits'] / cache_total) * 100,
            'error_rate': (snapshot['errors'] / total_requests) * 100,
            'avg_response_time': snapshot['avg_response_time'],
            'max_response_time': snapshot['max_response_time'],
            'min_response_time': snapshot['min_response_time'],
            'circuit_breaker_state': self._circuit_breaker.state,
            'circuit_breaker_failures': self._circuit_breaker.failure_count,
            'cache_size': len(self._cache),
            'connection_pool_size': len(self._sessions),
            'last_request_time': snapshot['last_request_time']
        }
    
    async def _make_request_with_cache(
        self,
        method: str,
        url: str,
        params: dict = None,
        data: dict = None,
        use_cache: bool = True,
    ) -> Tuple[int, Any]:
        """å¸¦ç¼“å­˜çš„HTTPè¯·æ±‚æ–¹æ³•"""
        start_time = time.time()

        if not self._check_rate_limit():
            raise QbtRateLimitError("APIè¯·æ±‚é¢‘ç‡è¶…é™")

        if not self._check_circuit_breaker():
            raise QBittorrentError("æœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼ˆæ–­è·¯å™¨æ‰“å¼€ï¼‰")

        cache_key = None
        if use_cache and method.upper() == 'GET':
            cache_key = self._get_cache_key(method, url, params, data)
            cached_result = self._get_from_cache(cache_key)
            if cached_result:
                self.logger.debug(f"ç¼“å­˜å‘½ä¸­: {method} {url}")
                return cached_result

        session = await self._get_next_session()

        try:
            self._metrics.inc('requests')
            self._metrics.update_last_request_time(datetime.now().isoformat())

            if method.upper() == 'GET':
                async with session.get(url, params=params) as resp:
                    status = resp.status
                    if resp.content_type == 'application/json':
                        result = await resp.json()
                    else:
                        result = await resp.text()
            else:
                async with session.post(url, data=data, params=params) as resp:
                    status = resp.status
                    if resp.content_type == 'application/json':
                        result = await resp.json()
                    else:
                        result = await resp.text()

            response_time = time.time() - start_time
            self._metrics.record_response(response_time)

            if 200 <= status < 300:
                self._record_success()
                if use_cache and method.upper() == 'GET' and cache_key:
                    self._put_to_cache(cache_key, (status, result))
                return status, result

            self._metrics.inc('errors')
            if status >= 500:
                self._record_failure()

            if status == 403:
                raise QbtPermissionError(f"æƒé™ä¸è¶³: {result}")
            if status == 429:
                raise QbtRateLimitError(f"è¯·æ±‚è¿‡äºé¢‘ç¹: {result}")
            raise QBittorrentError(f"è¯·æ±‚å¤±è´¥ (HTTP {status}): {result}")

        except aiohttp.ClientError as e:
            self._metrics.inc('errors')
            self._record_failure()
            raise NetworkError(f"ç½‘ç»œè¯·æ±‚é”™è¯¯: {str(e)}") from e
        except Exception as e:
            self._metrics.inc('errors')
            self._record_failure()
            raise

    @retry(
        stop=stop_after_attempt(3),
        wait=wait_exponential(multiplier=0.5, min=0.5, max=5),
        retry=retry_if_exception_type((NetworkError, QbtRateLimitError)),
        before_sleep=before_sleep_log(logging.getLogger('QBittorrent.Retry'), logging.INFO)
    )
    async def login(self):
        """ç™»å½•qBittorrent"""
        url = f"{self._base_url}/api/v2/auth/login"
        data = {
            'username': self.config.username,
            'password': self.config.password
        }
        
        try:
            self.logger.info(f"å°è¯•ç™»å½•qBittorrent: {self.config.host}:{self.config.port}")
            async with self.session.post(url, data=data) as resp:
                if resp.status == 200:
                    response_text = await resp.text()
                    if response_text == "Ok.":
                        self._authenticated = True
                        self.logger.info("æˆåŠŸç™»å½•qBittorrent")
                        return
                    else:
                        raise QbtAuthError(f"ç™»å½•å¤±è´¥: {response_text}")
                elif resp.status == 403:
                    raise QbtAuthError("ç™»å½•å¤±è´¥: ç”¨æˆ·åæˆ–å¯†ç é”™è¯¯")
                elif resp.status == 429:
                    raise QbtRateLimitError("ç™»å½•å¤±è´¥: APIè¯·æ±‚è¿‡äºé¢‘ç¹")
                else:
                    error_text = await resp.text()
                    raise QBittorrentError(f"ç™»å½•å¤±è´¥: HTTP {resp.status} - {error_text}")
                    
        except aiohttp.ClientError as e:
            raise NetworkError(f"ç½‘ç»œè¿æ¥å¤±è´¥: {str(e)}") from e
    
    async def get_version(self) -> str:
        """è·å–qBittorrentç‰ˆæœ¬ä¿¡æ¯"""
        url = f"{self._base_url}/api/v2/app/version"
        try:
            async with self.session.get(url) as resp:
                if resp.status == 200:
                    return await resp.text()
                else:
                    raise QBittorrentError(f"è·å–ç‰ˆæœ¬å¤±è´¥: HTTP {resp.status}")
        except aiohttp.ClientError as e:
            raise NetworkError(f"è·å–ç‰ˆæœ¬å¤±è´¥: {str(e)}") from e
    
    async def get_existing_categories(self) -> Dict[str, Dict[str, Any]]:
        """è·å–ç°æœ‰çš„åˆ†ç±»åŠå…¶è¯¦ç»†ä¿¡æ¯"""
        url = f"{self._base_url}/api/v2/torrents/categories"
        
        try:
            async with self.session.get(url) as resp:
                if resp.status == 200:
                    content_type = resp.headers.get('Content-Type', '')
                    if 'application/json' not in content_type:
                        raise QBittorrentError(f"è·å–åˆ†ç±»å¤±è´¥: å“åº”ç±»å‹é”™è¯¯ ({content_type})")
                    
                    response_text = await resp.text()
                    if not response_text.strip():
                        self.logger.warning("qBittorrentè¿”å›ç©ºçš„åˆ†ç±»åˆ—è¡¨")
                        return {}
                    
                    categories = json.loads(response_text)
                    self.logger.info(f"è·å–åˆ° {len(categories)} ä¸ªç°æœ‰åˆ†ç±»")
                    return categories
                    
                elif resp.status == 403:
                    raise QbtPermissionError("è·å–åˆ†ç±»å¤±è´¥: æƒé™ä¸è¶³")
                else:
                    error_text = await resp.text()
                    raise QBittorrentError(f"è·å–åˆ†ç±»å¤±è´¥: HTTP {resp.status} - {error_text}")
                    
        except aiohttp.ClientError as e:
            raise NetworkError(f"è·å–åˆ†ç±»å¤±è´¥: {str(e)}") from e
        except json.JSONDecodeError as e:
            raise QBittorrentError(f"è§£æåˆ†ç±»å“åº”å¤±è´¥: {str(e)}") from e
    
    async def ensure_categories(self, categories: Dict[str, CategoryConfig]):
        """ç¡®ä¿æ‰€æœ‰åˆ†ç±»å­˜åœ¨ï¼ŒåŠ¨æ€æ›´æ–°åˆ†ç±»è·¯å¾„"""
        try:
            existing_categories = await self.get_existing_categories()
            
            for name, config in categories.items():
                mapped_path = self._map_save_path(config.save_path, name)
                self.logger.info(f"å¤„ç†åˆ†ç±»: {name}, æ˜ å°„è·¯å¾„: {mapped_path}")
                
                if name not in existing_categories:
                    self.logger.info(f"åˆ›å»ºæ–°åˆ†ç±»: {name}")
                    await self._create_category(name, mapped_path)
                else:
                    # åŠ¨æ€æ›´æ–°åˆ†ç±»è·¯å¾„
                    existing_path = existing_categories[name].get('savePath', '')
                    if existing_path != mapped_path:
                        self.logger.info(f"æ›´æ–°åˆ†ç±»è·¯å¾„: {name} (å½“å‰è·¯å¾„: {existing_path} -> æ–°è·¯å¾„: {mapped_path})")
                        await self._update_category(name, mapped_path)
                    else:
                        self.logger.info(f"åˆ†ç±»è·¯å¾„æœªå˜ï¼Œè·³è¿‡æ›´æ–°: {name} (è·¯å¾„: {existing_path})")
                        
        except Exception as e:
            self.logger.error(f"åˆ†ç±»ç®¡ç†å¤±è´¥: {str(e)}")
            # ä¸å†æŠ›å‡ºå¼‚å¸¸ï¼Œå…è®¸ç¨‹åºç»§ç»­è¿è¡Œ
            self.logger.warning("åˆ†ç±»ç®¡ç†å¤±è´¥ï¼Œä½†ç¨‹åºå°†ç»§ç»­è¿è¡Œ")
    
    async def _create_category(self, name: str, save_path: str):
        """åˆ›å»ºæ–°åˆ†ç±»"""
        url = f"{self._base_url}/api/v2/torrents/createCategory"
        data = {'category': name, 'savePath': save_path}
        
        try:
            async with self.session.post(url, data=data) as resp:
                if resp.status == 200:
                    self.logger.info(f"åˆ›å»ºåˆ†ç±»æˆåŠŸ: {name} -> {save_path}")
                elif resp.status == 409:
                    self.logger.warning(f"åˆ†ç±»å·²å­˜åœ¨: {name}")
                else:
                    error_text = await resp.text()
                    raise QBittorrentError(f"åˆ›å»ºåˆ†ç±»å¤±è´¥: {error_text}")
                    
        except aiohttp.ClientError as e:
            raise NetworkError(f"åˆ›å»ºåˆ†ç±»ç½‘ç»œé”™è¯¯: {str(e)}") from e
    
    async def _update_category(self, name: str, save_path: str):
        """æ›´æ–°ç°æœ‰åˆ†ç±»"""
        url = f"{self._base_url}/api/v2/torrents/editCategory"
        data = {'category': name, 'savePath': save_path}
        
        try:
            async with self.session.post(url, data=data) as resp:
                if resp.status == 200:
                    self.logger.info(f"æ›´æ–°åˆ†ç±»æˆåŠŸ: {name} -> {save_path}")
                elif resp.status == 409:
                    # å¦‚æœæ›´æ–°å¤±è´¥ï¼Œå°è¯•å…ˆåˆ é™¤å†åˆ›å»º
                    self.logger.warning(f"æ›´æ–°åˆ†ç±»å¤±è´¥ï¼Œå°è¯•é‡æ–°åˆ›å»º: {name}")
                    await self._delete_category(name)
                    await self._create_category(name, save_path)
                else:
                    error_text = await resp.text()
                    # å½“æ›´æ–°åˆ†ç±»å¤±è´¥æ—¶ï¼Œå°è¯•åˆ é™¤å¹¶é‡æ–°åˆ›å»º
                    self.logger.warning(f"æ›´æ–°åˆ†ç±»å¤±è´¥: {error_text}ï¼Œå°è¯•é‡æ–°åˆ›å»º")
                    await self._delete_category(name)
                    await self._create_category(name, save_path)
                    
        except aiohttp.ClientError as e:
            raise NetworkError(f"æ›´æ–°åˆ†ç±»ç½‘ç»œé”™è¯¯: {str(e)}") from e
    
    async def _delete_category(self, name: str):
        """åˆ é™¤åˆ†ç±»"""
        url = f"{self._base_url}/api/v2/torrents/removeCategories"
        data = {'categories': name}
        
        try:
            async with self.session.post(url, data=data) as resp:
                if resp.status == 200:
                    self.logger.info(f"åˆ é™¤åˆ†ç±»æˆåŠŸ: {name}")
                else:
                    error_text = await resp.text()
                    raise QBittorrentError(f"åˆ é™¤åˆ†ç±»å¤±è´¥: {error_text}")
        except aiohttp.ClientError as e:
            raise NetworkError(f"åˆ é™¤åˆ†ç±»ç½‘ç»œé”™è¯¯: {str(e)}") from e
    
    def _map_save_path(self, original_path: str, category_name: str = "") -> str:
        """å¢å¼ºçš„è·¯å¾„æ˜ å°„åŠŸèƒ½"""
        if not self.app_config:
            return original_path
        
        # å¦‚æœé…ç½®ä¸ºç›´æ¥ä½¿ç”¨NASè·¯å¾„
        if self.app_config.use_nas_paths_directly or self.config.use_nas_paths_directly:
            return original_path
        
        # ä¼˜å…ˆä½¿ç”¨æ–°çš„è·¯å¾„æ˜ å°„è§„åˆ™
        if self.config.path_mapping:
            for mapping in self.config.path_mapping:
                if original_path.startswith(mapping.source_prefix):
                    mapped_path = original_path.replace(
                        mapping.source_prefix, 
                        mapping.target_prefix, 
                        1
                    )
                    self.logger.debug(
                        f"è·¯å¾„æ˜ å°„ ({mapping.description or 'N/A'}): "
                        f"{original_path} -> {mapped_path}"
                    )
                    return mapped_path
        
        # å›é€€åˆ°ä¼ ç»Ÿçš„å…¨å±€è·¯å¾„æ˜ å°„
        for source, target in self.app_config.path_mapping.items():
            if original_path.startswith(source):
                mapped_path = original_path.replace(source, target, 1)
                self.logger.debug(f"å…¨å±€è·¯å¾„æ˜ å°„: {original_path} -> {mapped_path}")
                return mapped_path
        
        # æ²¡æœ‰åŒ¹é…çš„è§„åˆ™ï¼Œè¿”å›åŸå§‹è·¯å¾„
        self.logger.debug(f"æ— è·¯å¾„æ˜ å°„è§„åˆ™åŒ¹é…ï¼Œä½¿ç”¨åŸå§‹è·¯å¾„: {original_path}")
        return original_path
    
    @retry(
        stop=stop_after_attempt(3),
        wait=wait_exponential(multiplier=1, min=1, max=3),
        retry=retry_if_exception_type((NetworkError, QbtRateLimitError)),
        before_sleep=before_sleep_log(logging.getLogger('QBittorrent.AddTorrent'), logging.INFO)
    )
    async def add_torrent(self, magnet_link: str, category: str, **kwargs) -> bool:
        """æ·»åŠ ç£åŠ›é“¾æ¥ï¼Œæ”¯æŒæ›´å¤šé€‰é¡¹"""
        try:
            # è§£æç£åŠ›é“¾æ¥ï¼Œæä¾›é»˜è®¤åç§°
            torrent_hash, torrent_name = parse_magnet(magnet_link)
            if not torrent_hash:
                raise TorrentParseError("æ— æ•ˆçš„ç£åŠ›é“¾æ¥æ ¼å¼")
            
            # å¦‚æœç£åŠ›é“¾æ¥æ²¡æœ‰dnå‚æ•°ï¼Œå°è¯•ä»ç§å­å±æ€§è·å–åç§°
            display_name = torrent_name or f"ç£åŠ›é“¾æ¥_{torrent_hash[:8]}"
            self.logger.debug(f"åŸå§‹ç£åŠ›é“¾æ¥æ–‡ä»¶å: {torrent_name}")
            
            # æ£€æŸ¥æ˜¯å¦é‡å¤
            if await self._is_duplicate(torrent_hash):
                self.logger.info(f"è·³è¿‡é‡å¤ç§å­: {display_name}")
                return False
            
            # éªŒè¯åˆ†ç±»å­˜åœ¨
            existing_categories = await self.get_existing_categories()
            
            url = f"{self._base_url}/api/v2/torrents/add"
            data = {
                'urls': magnet_link,
                'autoTMM': 'false',  # å…³é—­è‡ªåŠ¨ç§å­ç®¡ç†
                **kwargs  # æ”¯æŒé¢å¤–å‚æ•°
            }
            
            # è®¾ç½®åˆ†ç±»
            if category in existing_categories:
                data['category'] = category
                save_path = existing_categories[category]['savePath']
                self.logger.info(f"ç§å­å°†æ·»åŠ åˆ°åˆ†ç±»: {category} ({save_path})")
            else:
                self.logger.warning(f"åˆ†ç±»ä¸å­˜åœ¨: {category}ï¼Œå°†ä½¿ç”¨é»˜è®¤è·¯å¾„")
            
            # é¦–æ¬¡å°è¯•æ·»åŠ ç§å­
            async with self.session.post(url, data=data) as resp:
                if resp.status == 200:
                    response_text = await resp.text()
                    if response_text != "Fails.":
                        # ç§å­æ·»åŠ æˆåŠŸï¼Œè·å–å®é™…çš„ç§å­åç§°ï¼ˆä½†ä¸å¼ºåˆ¶é‡å‘½åï¼‰
                        try:
                            # ç­‰å¾…çŸ­æš‚æ—¶é—´è®©qBittorrentå¤„ç†ç§å­
                            await asyncio.sleep(1)
                            torrent_info = await self.get_torrent_properties(torrent_hash)
                            if 'name' in torrent_info and torrent_info['name']:
                                actual_name = torrent_info['name']
                                self.logger.info(f"æˆåŠŸæ·»åŠ ç§å­: {actual_name}")
                            else:
                                self.logger.info(f"æˆåŠŸæ·»åŠ ç§å­: {display_name}")
                        except Exception as e:
                            self.logger.warning(f"è·å–ç§å­å±æ€§å¤±è´¥ä½†ä¸å½±å“æ·»åŠ : {str(e)}")
                            self.logger.info(f"æˆåŠŸæ·»åŠ ç§å­: {display_name}")
                        
                        return True
                    else:
                        raise QBittorrentError("æ·»åŠ ç§å­å¤±è´¥: qBittorrentè¿”å›Fails")
                elif resp.status == 403:
                    raise QbtPermissionError("æ·»åŠ ç§å­å¤±è´¥: æƒé™ä¸è¶³")
                elif resp.status == 429:
                    raise QbtRateLimitError("æ·»åŠ ç§å­å¤±è´¥: APIè¯·æ±‚è¿‡äºé¢‘ç¹")
                else:
                    error_text = await resp.text()
                    raise QBittorrentError(f"æ·»åŠ ç§å­å¤±è´¥: HTTP {resp.status} - {error_text}")
                    
        except TorrentParseError:
            raise
        except aiohttp.ClientError as e:
            raise NetworkError(f"æ·»åŠ ç§å­ç½‘ç»œé”™è¯¯: {str(e)}") from e
    
    async def _rename_torrent(self, torrent_hash: str, new_name: str) -> bool:
        """é‡å‘½åç§å­ä»¥ä¿æŒåŸå§‹åç§°"""
        try:
            # æ¸…ç†æ–‡ä»¶åä¸­çš„éæ³•å­—ç¬¦
            import re
            new_name = re.sub(r'[\\/:*?"<>|]', '_', new_name)
            new_name = new_name.strip()
            
            # ä½¿ç”¨æ­£ç¡®çš„qBittorrent APIç«¯ç‚¹
            url = f"{self._base_url}/api/v2/torrents/rename"
            data = {
                'hash': torrent_hash,
                'name': new_name
            }
            
            self.logger.info(f"ğŸ”„ å°è¯•é‡å‘½åç§å­: {torrent_hash[:8]} -> {new_name}")
            
            async with self.session.post(url, data=data) as resp:
                response_text = await resp.text()
                if resp.status == 200:
                    self.logger.info(f"âœ… ç§å­é‡å‘½åæˆåŠŸ: {new_name}")
                    return True
                else:
                    self.logger.warning(f"âš ï¸ ç§å­é‡å‘½åå¤±è´¥ (HTTP {resp.status}): {response_text}")
                    
                    # å°è¯•å¤‡ç”¨æ–¹æ³•ï¼šä½¿ç”¨setNameç«¯ç‚¹
                    return await self._set_torrent_name_alternative(torrent_hash, new_name)
        except Exception as e:
            self.logger.warning(f"âš ï¸ ç§å­é‡å‘½åå¼‚å¸¸: {str(e)}")
            # å°è¯•å¤‡ç”¨æ–¹æ³•
            return await self._set_torrent_name_alternative(torrent_hash, new_name)

    async def _set_torrent_name_alternative(self, torrent_hash: str, new_name: str) -> bool:
        """å¤‡ç”¨é‡å‘½åæ–¹æ³•ï¼šä½¿ç”¨setNameç«¯ç‚¹"""
        try:
            url = f"{self._base_url}/api/v2/torrents/setName"
            data = {
                'hash': torrent_hash,
                'name': new_name
            }
            
            self.logger.info(f"ğŸ”„ ä½¿ç”¨å¤‡ç”¨æ–¹æ³•é‡å‘½å: {torrent_hash[:8]} -> {new_name}")
            
            async with self.session.post(url, data=data) as resp:
                response_text = await resp.text()
                if resp.status == 200:
                    self.logger.info(f"âœ… å¤‡ç”¨é‡å‘½åæˆåŠŸ: {new_name}")
                    return True
                else:
                    self.logger.warning(f"âš ï¸ å¤‡ç”¨é‡å‘½åä¹Ÿå¤±è´¥ (HTTP {resp.status}): {response_text}")
                    return False
        except Exception as e:
            self.logger.warning(f"âš ï¸ å¤‡ç”¨é‡å‘½åå¼‚å¸¸: {str(e)}")
            return False
    
    async def _is_duplicate(self, torrent_hash: str) -> bool:
        """æ£€æŸ¥ç§å­æ˜¯å¦å·²å­˜åœ¨"""
        url = f"{self._base_url}/api/v2/torrents/info"
        params = {'hashes': torrent_hash}
        
        try:
            async with self.session.get(url, params=params) as resp:
                if resp.status == 200:
                    torrents = await resp.json()
                    return len(torrents) > 0
                else:
                    self.logger.warning(f"æ£€æŸ¥é‡å¤å¤±è´¥: HTTP {resp.status}")
                    return False
        except aiohttp.ClientError as e:
            self.logger.warning(f"æ£€æŸ¥é‡å¤ç½‘ç»œé”™è¯¯: {str(e)}")
            return False
    
    async def get_torrents(self, category: Optional[str] = None) -> List[Dict[str, Any]]:
        """è·å–ç§å­åˆ—è¡¨"""
        url = f"{self._base_url}/api/v2/torrents/info"
        params = {}
        if category:
            params['category'] = category
        
        try:
            async with self.session.get(url, params=params) as resp:
                if resp.status == 200:
                    return await resp.json()
                else:
                    error_text = await resp.text()
                    raise QBittorrentError(f"è·å–ç§å­åˆ—è¡¨å¤±è´¥: {error_text}")
        except aiohttp.ClientError as e:
            raise NetworkError(f"è·å–ç§å­åˆ—è¡¨ç½‘ç»œé”™è¯¯: {str(e)}") from e
    
    async def delete_torrent(self, torrent_hash: str, delete_files: bool = False) -> bool:
        """åˆ é™¤ç§å­"""
        url = f"{self._base_url}/api/v2/torrents/delete"
        data = {
            'hashes': torrent_hash,
            'deleteFiles': 'true' if delete_files else 'false'
        }
        
        try:
            async with self.session.post(url, data=data) as resp:
                if resp.status == 200:
                    self.logger.info(f"åˆ é™¤ç§å­æˆåŠŸ: {torrent_hash[:8]}")
                    return True
                else:
                    error_text = await resp.text()
                    raise QBittorrentError(f"åˆ é™¤ç§å­å¤±è´¥: {error_text}")
        except aiohttp.ClientError as e:
            raise NetworkError(f"åˆ é™¤ç§å­ç½‘ç»œé”™è¯¯: {str(e)}") from e
    
    async def pause_torrent(self, torrent_hash: str) -> bool:
        """æš‚åœç§å­"""
        url = f"{self._base_url}/api/v2/torrents/pause"
        data = {'hashes': torrent_hash}
        
        try:
            async with self.session.post(url, data=data) as resp:
                if resp.status == 200:
                    self.logger.info(f"æš‚åœç§å­æˆåŠŸ: {torrent_hash[:8]}")
                    return True
                else:
                    error_text = await resp.text()
                    raise QBittorrentError(f"æš‚åœç§å­å¤±è´¥: {error_text}")
        except aiohttp.ClientError as e:
            raise NetworkError(f"æš‚åœç§å­ç½‘ç»œé”™è¯¯: {str(e)}") from e
    
    async def resume_torrent(self, torrent_hash: str) -> bool:
        """æ¢å¤ç§å­"""
        url = f"{self._base_url}/api/v2/torrents/resume"
        data = {'hashes': torrent_hash}
        
        try:
            async with self.session.post(url, data=data) as resp:
                if resp.status == 200:
                    self.logger.info(f"æ¢å¤ç§å­æˆåŠŸ: {torrent_hash[:8]}")
                    return True
                else:
                    error_text = await resp.text()
                    raise QBittorrentError(f"æ¢å¤ç§å­å¤±è´¥: {error_text}")
        except aiohttp.ClientError as e:
            raise NetworkError(f"æ¢å¤ç§å­ç½‘ç»œé”™è¯¯: {str(e)}") from e
    
    async def get_torrent_properties(self, torrent_hash: str) -> Dict[str, Any]:
        """è·å–ç§å­å±æ€§"""
        url = f"{self._base_url}/api/v2/torrents/properties"
        params = {'hash': torrent_hash}
        
        try:
            async with self.session.get(url, params=params) as resp:
                if resp.status == 200:
                    return await resp.json()
                else:
                    error_text = await resp.text()
                    raise QBittorrentError(f"è·å–ç§å­å±æ€§å¤±è´¥: {error_text}")
        except aiohttp.ClientError as e:
            raise NetworkError(f"è·å–ç§å­å±æ€§ç½‘ç»œé”™è¯¯: {str(e)}") from e
    
    async def get_torrent_files(self, torrent_hash: str) -> List[Dict[str, Any]]:
        """è·å–ç§å­æ–‡ä»¶åˆ—è¡¨"""
        url = f"{self._base_url}/api/v2/torrents/files"
        params = {'hash': torrent_hash}
        
        try:
            async with self.session.get(url, params=params) as resp:
                if resp.status == 200:
                    return await resp.json()
                else:
                    error_text = await resp.text()
                    raise QBittorrentError(f"è·å–ç§å­æ–‡ä»¶å¤±è´¥: {error_text}")
        except aiohttp.ClientError as e:
            raise NetworkError(f"è·å–ç§å­æ–‡ä»¶ç½‘ç»œé”™è¯¯: {str(e)}") from e


# ============================================================================
# ä¼˜åŒ–åçš„ qBittorrent å®¢æˆ·ç«¯ - æ”¯æŒå¤šçº§è¿æ¥æ± å’Œæ‰¹é‡æ“ä½œ
# ============================================================================

class OptimizedQBittorrentClient(QBittorrentClient):
    """
    ä¼˜åŒ–ç‰ˆ qBittorrent å®¢æˆ·ç«¯

    æ–°å¢åŠŸèƒ½ï¼š
    1. å¤šçº§è¿æ¥æ±  (è¯»ã€å†™ã€API åˆ†ç¦»)
    2. æ‰¹é‡æ“ä½œä¼˜åŒ–
    3. æ™ºèƒ½é”™è¯¯æ¢å¤
    4. æ€§èƒ½ç›‘æ§å¢å¼º
    """

    def __init__(self, config: QBittorrentConfig, app_config: Optional[AppConfig] = None):
        super().__init__(config, app_config)
        self.logger = logging.getLogger('OptimizedQBittorrentClient')

        # å¤šçº§è¿æ¥æ±  - ä¼˜åŒ–æŒ‡å¯¼æ–‡æ¡£å»ºè®®
        self._read_pool: Optional[aiohttp.ClientSession] = None
        self._write_pool: Optional[aiohttp.ClientSession] = None
        self._api_pool: Optional[aiohttp.ClientSession] = None

        # è¿æ¥æ± é…ç½®
        self._read_pool_size = getattr(config, 'read_pool_size', 10)
        self._write_pool_size = getattr(config, 'write_pool_size', 5)
        self._api_pool_size = getattr(config, 'api_pool_size', 20)

        # æ‰¹é‡æ“ä½œç»Ÿè®¡
        self._batch_stats = {
            'total_batches': 0,
            'successful_batches': 0,
            'failed_batches': 0,
            'total_items': 0,
            'avg_batch_size': 0.0
        }

    async def __aenter__(self):
        """å¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨ - åˆå§‹åŒ–å¤šçº§è¿æ¥æ± """
        # åˆå§‹åŒ–çˆ¶ç±»è¿æ¥æ± 
        await super().__aenter__()

        # åˆ›å»ºå¤šçº§è¿æ¥æ± 
        timeout = aiohttp.ClientTimeout(total=30, connect=10)

        # è¯»è¿æ¥æ±  - ç”¨äºè·å–æ•°æ®
        read_connector = aiohttp.TCPConnector(
            limit=self._read_pool_size,
            limit_per_host=5,
            keepalive_timeout=30
        )
        self._read_pool = aiohttp.ClientSession(
            timeout=timeout,
            connector=read_connector
        )

        # å†™è¿æ¥æ±  - ç”¨äºæ·»åŠ /ä¿®æ”¹æ•°æ®
        write_connector = aiohttp.TCPConnector(
            limit=self._write_pool_size,
            limit_per_host=3,
            keepalive_timeout=30
        )
        self._write_pool = aiohttp.ClientSession(
            timeout=timeout,
            connector=write_connector
        )

        # API è¿æ¥æ±  - ç”¨äºå¤æ‚æŸ¥è¯¢
        api_connector = aiohttp.TCPConnector(
            limit=self._api_pool_size,
            limit_per_host=10,
            keepalive_timeout=60
        )
        self._api_pool = aiohttp.ClientSession(
            timeout=timeout,
            connector=api_connector
        )

        self.logger.info(
            f"å¤šçº§è¿æ¥æ± åˆå§‹åŒ–å®Œæˆ: "
            f"è¯»({self._read_pool_size}) å†™({self._write_pool_size}) API({self._api_pool_size})"
        )
        return self

    async def cleanup(self):
        """æ¸…ç†æ‰€æœ‰èµ„æºï¼ŒåŒ…æ‹¬å¤šçº§è¿æ¥æ± """
        self.logger.info("å¼€å§‹æ¸…ç†ä¼˜åŒ–å®¢æˆ·ç«¯èµ„æº...")

        try:
            # å…³é—­å¤šçº§è¿æ¥æ± 
            if self._read_pool and not self._read_pool.closed:
                await self._read_pool.close()
                self.logger.debug("è¯»è¿æ¥æ± å·²å…³é—­")

            if self._write_pool and not self._write_pool.closed:
                await self._write_pool.close()
                self.logger.debug("å†™è¿æ¥æ± å·²å…³é—­")

            if self._api_pool and not self._api_pool.closed:
                await self._api_pool.close()
                self.logger.debug("APIè¿æ¥æ± å·²å…³é—­")

            # è°ƒç”¨çˆ¶ç±»æ¸…ç†
            await super().cleanup()

            self.logger.info("ä¼˜åŒ–å®¢æˆ·ç«¯èµ„æºæ¸…ç†å®Œæˆ")

        except Exception as e:
            self.logger.error(f"æ¸…ç†ä¼˜åŒ–å®¢æˆ·ç«¯èµ„æºæ—¶å‡ºé”™: {str(e)}")

    async def add_torrents_batch(
        self,
        torrents: List[Tuple[str, str]],
        batch_size: int = 10
    ) -> Dict[str, Any]:
        """
        æ‰¹é‡æ·»åŠ ç§å­ - ä¼˜åŒ–æŒ‡å¯¼æ–‡æ¡£å»ºè®®

        Args:
            torrents: [(magnet_link, category), ...] çš„åˆ—è¡¨
            batch_size: æ¯æ‰¹å¤„ç†çš„ç§å­æ•°é‡

        Returns:
            {
                'success_count': int,
                'failed_count': int,
                'skipped_count': int,
                'results': List[Dict]
            }
        """
        self.logger.info(f"å¼€å§‹æ‰¹é‡æ·»åŠ  {len(torrents)} ä¸ªç§å­ (æ‰¹æ¬¡å¤§å°: {batch_size})")
        self._batch_stats['total_batches'] += 1
        self._batch_stats['total_items'] += len(torrents)

        results = {
            'success_count': 0,
            'failed_count': 0,
            'skipped_count': 0,
            'results': []
        }

        # åˆ†æ‰¹å¤„ç†
        for i in range(0, len(torrents), batch_size):
            batch = torrents[i:i + batch_size]
            batch_num = i // batch_size + 1
            total_batches = (len(torrents) + batch_size - 1) // batch_size

            self.logger.info(f"å¤„ç†æ‰¹æ¬¡ {batch_num}/{total_batches} ({len(batch)} ä¸ªç§å­)")

            # å¹¶å‘å¤„ç†å½“å‰æ‰¹æ¬¡
            tasks = []
            for magnet_link, category in batch:
                task = asyncio.create_task(
                    self._add_torrent_safe(magnet_link, category)
                )
                tasks.append(task)

            batch_results = await asyncio.gather(*tasks, return_exceptions=True)

            # å¤„ç†æ‰¹æ¬¡ç»“æœ
            for j, result in enumerate(batch_results):
                magnet_link, category = batch[j]

                if isinstance(result, Exception):
                    self.logger.error(f"æ·»åŠ ç§å­å¤±è´¥: {magnet_link[:30]}... - {str(result)}")
                    results['failed_count'] += 1
                    results['results'].append({
                        'magnet': magnet_link,
                        'category': category,
                        'status': 'failed',
                        'error': str(result)
                    })
                elif result is True:
                    results['success_count'] += 1
                    results['results'].append({
                        'magnet': magnet_link,
                        'category': category,
                        'status': 'success'
                    })
                elif result is False:
                    results['skipped_count'] += 1
                    results['results'].append({
                        'magnet': magnet_link,
                        'category': category,
                        'status': 'skipped',
                        'reason': 'duplicate'
                    })

        # æ›´æ–°ç»Ÿè®¡
        if results['failed_count'] == 0:
            self._batch_stats['successful_batches'] += 1
        else:
            self._batch_stats['failed_batches'] += 1

        avg_size = self._batch_stats['total_items'] / max(self._batch_stats['total_batches'], 1)
        self._batch_stats['avg_batch_size'] = avg_size

        self.logger.info(
            f"æ‰¹é‡æ·»åŠ å®Œæˆ: æˆåŠŸ {results['success_count']}, "
            f"å¤±è´¥ {results['failed_count']}, è·³è¿‡ {results['skipped_count']}"
        )

        return results

    async def _add_torrent_safe(self, magnet_link: str, category: str) -> bool:
        """å®‰å…¨æ·»åŠ å•ä¸ªç§å­ (ç”¨äºæ‰¹é‡æ“ä½œ)"""
        try:
            # ä½¿ç”¨å†™è¿æ¥æ± 
            result = await self.add_torrent(magnet_link, category)
            return result
        except Exception as e:
            self.logger.error(f"æ‰¹é‡æ·»åŠ å¤±è´¥: {magnet_link[:30]}... - {str(e)}")
            raise

    async def get_torrents_batch(
        self,
        hashes: List[str],
        batch_size: int = 50
    ) -> Dict[str, Any]:
        """
        æ‰¹é‡è·å–ç§å­ä¿¡æ¯ - ä¼˜åŒ–æŒ‡å¯¼æ–‡æ¡£å»ºè®®

        Args:
            hashes: ç§å­å“ˆå¸Œåˆ—è¡¨
            batch_size: æ¯æ‰¹æŸ¥è¯¢çš„æ•°é‡

        Returns:
            {
                'total': int,
                'found': int,
                'not_found': int,
                'torrents': Dict[hash, torrent_info]
            }
        """
        self.logger.info(f"å¼€å§‹æ‰¹é‡è·å– {len(hashes)} ä¸ªç§å­ä¿¡æ¯")

        results = {
            'total': len(hashes),
            'found': 0,
            'not_found': 0,
            'torrents': {}
        }

        # åˆ†æ‰¹æŸ¥è¯¢
        for i in range(0, len(hashes), batch_size):
            batch = hashes[i:i + batch_size]
            batch_num = i // batch_size + 1
            total_batches = (len(hashes) + batch_size - 1) // batch_size

            self.logger.debug(f"æŸ¥è¯¢æ‰¹æ¬¡ {batch_num}/{total_batches}")

            # æ„é€ æŸ¥è¯¢å‚æ•°
            params = {}
            if len(batch) == 1:
                # å•ä¸ªæŸ¥è¯¢
                params['hashes'] = batch[0]
            else:
                # æ‰¹é‡æŸ¥è¯¢ (ç”¨ | åˆ†éš”)
                params['hashes'] = '|'.join(batch)

            try:
                # ä½¿ç”¨è¯»è¿æ¥æ± æŸ¥è¯¢
                url = f"{self._base_url}/api/v2/torrents/info"
                async with self._read_pool.get(url, params=params) as resp:
                    if resp.status == 200:
                        torrents = await resp.json()

                        # å¤„ç†è¿”å›çš„ç§å­ä¿¡æ¯
                        found_hashes = set()
                        for torrent in torrents:
                            hash_value = torrent.get('hash', '').lower()
                            if hash_value:
                                results['torrents'][hash_value] = torrent
                                found_hashes.add(hash_value)

                        # æ›´æ–°è®¡æ•°
                        results['found'] += len(found_hashes)
                        results['not_found'] += len(batch) - len(found_hashes)

                        self.logger.debug(f"æ‰¹æ¬¡ {batch_num}: æ‰¾åˆ° {len(found_hashes)}/{len(batch)} ä¸ªç§å­")
                    else:
                        error_text = await resp.text()
                        self.logger.error(f"æ‰¹æ¬¡ {batch_num} æŸ¥è¯¢å¤±è´¥: {error_text}")
                        results['not_found'] += len(batch)

            except Exception as e:
                self.logger.error(f"æ‰¹æ¬¡ {batch_num} æŸ¥è¯¢å¼‚å¸¸: {str(e)}")
                results['not_found'] += len(batch)

        self.logger.info(
            f"æ‰¹é‡æŸ¥è¯¢å®Œæˆ: æ‰¾åˆ° {results['found']}/{results['total']} ä¸ªç§å­"
        )

        return results

    async def get_torrents_by_category_batch(
        self,
        categories: List[str],
        use_api_pool: bool = True
    ) -> Dict[str, Any]:
        """
        æŒ‰åˆ†ç±»æ‰¹é‡è·å–ç§å­ - ä½¿ç”¨ API è¿æ¥æ± 

        Args:
            categories: åˆ†ç±»åˆ—è¡¨
            use_api_pool: æ˜¯å¦ä½¿ç”¨ API è¿æ¥æ± 

        Returns:
            Dict[category, List[torrent_info]]
        """
        self.logger.info(f"æŒ‰åˆ†ç±»æ‰¹é‡è·å–ç§å­: {categories}")

        results = {}

        # å¹¶å‘æŸ¥è¯¢æ‰€æœ‰åˆ†ç±»
        tasks = []
        for category in categories:
            task = asyncio.create_task(
                self._get_torrents_by_category_safe(category, use_api_pool)
            )
            tasks.append((category, task))

        for category, task in tasks:
            try:
                torrents = await task
                results[category] = torrents
                self.logger.debug(f"åˆ†ç±» '{category}': {len(torrents)} ä¸ªç§å­")
            except Exception as e:
                self.logger.error(f"è·å–åˆ†ç±» '{category}' å¤±è´¥: {str(e)}")
                results[category] = []

        return results

    async def _get_torrents_by_category_safe(
        self,
        category: str,
        use_api_pool: bool = True
    ) -> List[Dict[str, Any]]:
        """å®‰å…¨æŒ‰åˆ†ç±»è·å–ç§å­"""
        url = f"{self._base_url}/api/v2/torrents/info"
        params = {'category': category}

        session = self._api_pool if use_api_pool else self.session
        async with session.get(url, params=params) as resp:
            if resp.status == 200:
                return await resp.json()
            else:
                error_text = await resp.text()
                raise QBittorrentError(f"è·å–åˆ†ç±» '{category}' å¤±è´¥: {error_text}")

    def get_batch_stats(self) -> Dict[str, Any]:
        """è·å–æ‰¹é‡æ“ä½œç»Ÿè®¡ä¿¡æ¯"""
        stats = self._batch_stats.copy()

        if stats['total_batches'] > 0:
            stats['success_rate'] = (
                stats['successful_batches'] / stats['total_batches'] * 100
            )
        else:
            stats['success_rate'] = 0.0

        return stats

    async def _smart_retry_with_different_params(self, error: Exception) -> Any:
        """
        æ™ºèƒ½é”™è¯¯æ¢å¤ - ä¼˜åŒ–æŒ‡å¯¼æ–‡æ¡£å»ºè®®
        æ ¹æ®é”™è¯¯ç±»å‹ä½¿ç”¨ä¸åŒçš„é‡è¯•ç­–ç•¥
        """
        if isinstance(error, QbtRateLimitError):
            # é™æµé”™è¯¯ï¼šç­‰å¾…æ›´é•¿æ—¶é—´
            self.logger.warning("æ£€æµ‹åˆ° API é™æµï¼Œç­‰å¾…åé‡è¯•...")
            await asyncio.sleep(5)
            # é™ä½å¹¶å‘åº¦
            return await self._retry_with_reduced_concurrency()
        elif isinstance(error, QbtPermissionError):
            # æƒé™é”™è¯¯ï¼šä¸é‡è¯•ï¼Œç›´æ¥æŠ›å‡º
            raise QBittorrentError("æƒé™ä¸è¶³ï¼Œæ— æ³•é‡è¯•")
        elif isinstance(error, NetworkError):
            # ç½‘ç»œé”™è¯¯ï¼šæŒ‡æ•°é€€é¿é‡è¯•
            self.logger.warning("ç½‘ç»œé”™è¯¯ï¼ŒæŒ‡æ•°é€€é¿é‡è¯•...")
            await asyncio.sleep(2)
            return await self._retry_with_backoff()
        else:
            # å…¶ä»–é”™è¯¯ï¼šæ ‡å‡†é‡è¯•
            raise

    async def _retry_with_reduced_concurrency(self) -> Any:
        """é™ä½å¹¶å‘åº¦é‡è¯•"""
        # è¿™é‡Œå¯ä»¥åŠ¨æ€è°ƒæ•´è¿æ¥æ± å¤§å°
        # æš‚æ—¶è¿”å› False è¡¨ç¤ºéœ€è¦é™ä½å¹¶å‘
        return False

    async def _retry_with_backoff(self) -> Any:
        """æŒ‡æ•°é€€é¿é‡è¯•"""
        await asyncio.sleep(1)
        return True
