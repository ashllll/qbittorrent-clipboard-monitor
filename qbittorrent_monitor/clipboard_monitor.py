"""
å¢å¼ºçš„å‰ªè´´æ¿ç›‘æ§å™¨æ¨¡å—

æ”¯æŒï¼š
- æ™ºèƒ½å‰ªè´´æ¿ç›‘æ§
- ä¸°å¯Œçš„é€šçŸ¥é›†æˆ
- é”™è¯¯æ¢å¤
- å†å²è®°å½•
- å®æ—¶ç»Ÿè®¡
"""

import asyncio
import logging
import threading
import time
from collections import deque
from datetime import datetime, timedelta
from typing import Optional, Dict, List, Set

from .config import AppConfig
from .qbittorrent_client import QBittorrentClient
from .ai_classifier import AIClassifier
from .clipboard_poller import ClipboardPoller, PollerConfig
from .clipboard_processor import ClipboardContentProcessor
from .clipboard_actions import ClipboardActionExecutor
from .clipboard_models import TorrentRecord
from .notifications import NotificationManager
from .exceptions import ClipboardError
from .workflow_engine import initialize_workflow_engine, get_workflow_engine


class ClipboardMonitor:
    """é«˜æ€§èƒ½å¼‚æ­¥å‰ªè´´æ¿ç›‘æ§å™¨
    
    ä¼˜åŒ–ç‰¹æ€§:
    - å¼‚æ­¥å‰ªè´´æ¿è®¿é—®ï¼Œé¿å…é˜»å¡äº‹ä»¶å¾ªç¯
    - æ™ºèƒ½è½®è¯¢é—´éš”è°ƒæ•´ï¼Œå‡å°‘CPUä½¿ç”¨
    - å†…å­˜ç®¡ç†ä¼˜åŒ–ï¼Œé˜²æ­¢å†…å­˜æ³„æ¼
    - é‡å¤æ£€æµ‹ç¼“å­˜ï¼Œæå‡æ€§èƒ½
    - é”™è¯¯æ¢å¤æœºåˆ¶ï¼Œå¢å¼ºç¨³å®šæ€§
    """
    
    def __init__(self, qbt: QBittorrentClient, config: AppConfig):
        self.qbt = qbt
        self.config = config
        self.logger = logging.getLogger('ClipboardMonitor')
        
        self.last_clip = ""

        # æå‰åˆå§‹åŒ–ç›‘æ§çŠ¶æ€ï¼Œç¡®ä¿å¼‚å¸¸æ—¶ä¹Ÿå¯å®‰å…¨æ¸…ç†
        self.history: deque = deque(maxlen=1000)
        self._duplicate_cache: Set[str] = set()
        self._cache_cleanup_time = datetime.now()
        self._max_cache_size = 10000
        self.stats = {
            'total_processed': 0,
            'successful_adds': 0,
            'failed_adds': 0,
            'duplicates_skipped': 0,
            'ai_classifications': 0,
            'rule_classifications': 0,
            'url_crawls': 0,
            'batch_adds': 0,
            'clipboard_reads': 0,  # æ–°å¢ï¼šå‰ªè´´æ¿è¯»å–æ¬¡æ•°
            'cache_hits': 0,       # æ–°å¢ï¼šç¼“å­˜å‘½ä¸­æ¬¡æ•°
            'performance_metrics': {
                'avg_process_time': 0.0,
                'max_process_time': 0.0,
                'total_process_time': 0.0
            }
        }
        self.is_running = False
        self.last_error_time: Optional[datetime] = None
        self.consecutive_errors = 0
        self.last_stats_report = datetime.now()
        self._process_times: deque = deque(maxlen=100)
        self._is_cleaned_up = False
        self._cleanup_lock = asyncio.Lock()

        # åˆå§‹åŒ–AIåˆ†ç±»å™¨ & é€šçŸ¥ç»„ä»¶
        self.ai_classifier = AIClassifier(config.deepseek)
        self.notification_manager = NotificationManager(config.notifications.model_dump())
        self.content_processor = ClipboardContentProcessor()
        self.action_executor = ClipboardActionExecutor(
            self.qbt,
            self.config,
            self.ai_classifier,
            self.notification_manager,
            self.stats,
            self._add_to_history,
            logger=self.logger,
        )

        base_interval = max(0.5, min(config.check_interval, 5.0))
        poller_config = PollerConfig(base_interval=base_interval)
        self.poller = ClipboardPoller(poller_config, self._on_clipboard_change)
        self._pending_clip: Optional[str] = None
        self._clip_event = asyncio.Event()
        self._base_interval = poller_config.base_interval
        self._max_interval = poller_config.max_interval
        
    async def start(self):
        """å¯åŠ¨å‰ªè´´æ¿ç›‘æ§å¾ªç¯"""
        self.is_running = True
        self.logger.info("å¼€å§‹ç›‘æ§å‰ªè´´æ¿...")

        # åˆå§‹åŒ–å¹¶å¯åŠ¨å·¥ä½œæµå¼•æ“
        try:
            self.workflow_engine = await initialize_workflow_engine(
                self.qbt,
                self.config,
                self.ai_classifier,
                self.notification_manager
            )
            self.logger.info("å·¥ä½œæµå¼•æ“å·²å¯åŠ¨")
        except Exception as e:
            self.logger.error(f"å·¥ä½œæµå¼•æ“å¯åŠ¨å¤±è´¥: {e}")
            self.workflow_engine = None

        # æ¬¢è¿æ¶ˆæ¯
        self._show_welcome_message()

        poller_task = asyncio.create_task(self.poller.start())
        try:
            while self.is_running:
                await self._clip_event.wait()
                self._clip_event.clear()
                clip = self._pending_clip
                self._pending_clip = None
                if clip is None:
                    continue

                cycle_start = time.time()
                await self._process_clipboard_text(clip)

                cycle_time = time.time() - cycle_start
                self._process_times.append(cycle_time)
                self._update_performance_metrics(cycle_time)

        except asyncio.CancelledError:
            self.logger.info("ç›‘æ§å·²å–æ¶ˆ")
            raise
        except Exception as e:
            self.logger.error(f"ç›‘æ§å¼‚å¸¸: {str(e)}")
            await self._handle_monitor_error(e)
            raise
        finally:
            self.is_running = False
            self.poller.stop()
            poller_task.cancel()
            try:
                await poller_task
            except asyncio.CancelledError:
                pass
            await self.cleanup()
            self.logger.info("å‰ªè´´æ¿ç›‘æ§å·²åœæ­¢")
            self._show_farewell_message()
    
    def stop(self):
        """åœæ­¢ç›‘æ§"""
        self.is_running = False
        self.poller.stop()
        self._clip_event.set()

    def _on_clipboard_change(self, text: str):
        """å¤„ç†å‰ªè´´æ¿å˜æ›´å›è°ƒ"""
        if not self.is_running:
            return
        self.stats['clipboard_reads'] = self.poller.clipboard_reads
        self._pending_clip = text or ""
        self._clip_event.set()
    
    async def _process_clipboard_text(self, current_clip: str):
        try:
            task = self.content_processor.process(current_clip)
            self.last_clip = current_clip or ""

            handled = False
            if task.kind == "magnet":
                await self.action_executor.handle_magnet(task.content)
                handled = True
            elif task.kind == "url":
                await self.action_executor.handle_url(task.content)
                handled = True

            # é‡ç½®é”™è¯¯è®¡æ•°
            self.consecutive_errors = 0
            self.last_error_time = None
            
            # å®šæœŸæ¸…ç†ç¼“å­˜å’ŒæŠ¥å‘Šç»Ÿè®¡
            if handled:
                await self._periodic_maintenance()
                
        except Exception as e:
            self.consecutive_errors += 1
            self.last_error_time = datetime.now()
            
            if self.consecutive_errors <= 3:
                self.logger.warning(f"ç›‘æ§å¾ªç¯é”™è¯¯ ({self.consecutive_errors}/3): {str(e)}")
            else:
                self.logger.error(f"è¿ç»­ç›‘æ§é”™è¯¯è¿‡å¤šï¼Œå¯èƒ½éœ€è¦é‡å¯: {str(e)}")
                await self._handle_monitor_error(e)
    
    def _update_performance_metrics(self, cycle_time: float):
        """æ›´æ–°æ€§èƒ½æŒ‡æ ‡"""
        # æ›´æ–°æ€§èƒ½æŒ‡æ ‡
        if self._process_times:
            avg_time = sum(self._process_times) / len(self._process_times)
            self.stats['performance_metrics']['avg_process_time'] = round(avg_time, 4)
            self.stats['performance_metrics']['total_process_time'] += cycle_time
        
        # è®°å½•æœ€å¤§å¤„ç†æ—¶é—´
        if cycle_time > self.stats['performance_metrics']['max_process_time']:
            self.stats['performance_metrics']['max_process_time'] = round(cycle_time, 4)
    
    async def _periodic_maintenance(self):
        """å®šæœŸç»´æŠ¤ä»»åŠ¡"""
        now = datetime.now()
        
        # æ¯5åˆ†é’Ÿæ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
        if (now - self.last_stats_report).total_seconds() >= 300:
            await self._periodic_stats_report()
            self.last_stats_report = now
        
        # æ¯å°æ—¶æ¸…ç†é‡å¤æ£€æµ‹ç¼“å­˜
        if (now - self._cache_cleanup_time).total_seconds() >= 3600:
            self._cleanup_duplicate_cache()
            self._cache_cleanup_time = now
    
    def _cleanup_duplicate_cache(self):
        """æ¸…ç†è¿‡æœŸçš„é‡å¤æ£€æµ‹ç¼“å­˜"""
        # å¦‚æœç¼“å­˜è¿‡å¤§ï¼Œæ¸…ç†ä¸€åŠ
        if len(self._duplicate_cache) > self._max_cache_size:
            # è½¬æ¢ä¸ºåˆ—è¡¨å¹¶ä¿ç•™åä¸€åŠ
            cache_list = list(self._duplicate_cache)
            self._duplicate_cache = set(cache_list[len(cache_list)//2:])
            self.logger.debug(f"æ¸…ç†äº† {len(cache_list)//2} ä¸ªç¼“å­˜é¡¹")
    
    def _show_welcome_message(self):
        """æ˜¾ç¤ºæ¬¢è¿æ¶ˆæ¯"""
        if self.config.notifications.console.enabled:
            welcome_lines = [
                "qBittorrentå¢å¼ºå‰ªè´´æ¿ç›‘æ§å·²å¯åŠ¨! (é«˜æ€§èƒ½ç‰ˆ v2.3.0)",
                f"åŸºç¡€ç›‘æ§é—´éš”: {self._base_interval}ç§’ (åŠ¨æ€è°ƒæ•´: {self._base_interval}-{self._max_interval}ç§’)",
                f"AIåˆ†ç±»å™¨: {'å·²å¯ç”¨' if hasattr(self.ai_classifier, 'client') and self.ai_classifier.client else 'ä½¿ç”¨è§„åˆ™å¼•æ“'}",
                f"é€šçŸ¥ç³»ç»Ÿ: {'å·²å¯ç”¨' if self.config.notifications.enabled else 'å·²ç¦ç”¨'}",
                f"æ€§èƒ½ä¼˜åŒ–: å¼‚æ­¥å‰ªè´´æ¿è®¿é—®ã€æ™ºèƒ½è½®è¯¢ã€å†…å­˜ç®¡ç†",
                "æ”¯æŒçš„å†…å®¹ç±»å‹:",
                "   ç£åŠ›é“¾æ¥ (magnet:) - è‡ªåŠ¨åˆ†ç±»æ·»åŠ ",
                "   ç½‘é¡µURL (http/https) - çˆ¬å–é¡µé¢å†…ç£åŠ›é“¾æ¥",
                "   XXXClubæœç´¢URL - æ‰¹é‡æŠ“å–ç§å­",
                "ä½¿ç”¨æ–¹æ³•:",
                "   å¤åˆ¶ç£åŠ›é“¾æ¥åˆ°å‰ªè´´æ¿ â†’ è‡ªåŠ¨æ·»åŠ å•ä¸ªç§å­",
                "   å¤åˆ¶XXXClubæœç´¢é¡µé¢URL â†’ æ‰¹é‡æŠ“å–å¹¶æ·»åŠ æ‰€æœ‰ç§å­",
                "æŒ‰Ctrl+Cåœæ­¢ç›‘æ§"
            ]

            if self.notification_manager.use_colors:
                from colorama import Fore, Style
                print(f"\n{Fore.GREEN}{'='*70}")
                for line in welcome_lines:
                    print(f"{Fore.GREEN}{line}")
                print(f"{'='*70}{Style.RESET_ALL}\n")
            else:
                print(f"\n{'='*70}")
                for line in welcome_lines:
                    print(line)
                print(f"{'='*70}\n")
    
    async def _classify_torrent_async(self, torrent_name: str) -> str:
        """å¼‚æ­¥åˆ†ç±»ç§å­"""
        if self.ai_classifier:
            try:
                return await self.ai_classifier.classify(torrent_name, self.config.categories)
            except Exception as e:
                self.logger.warning(f"AIåˆ†ç±»å¤±è´¥: {str(e)}")
                return self._classify_by_rules(torrent_name)
        else:
            return self._classify_by_rules(torrent_name)
    
    def _classify_by_rules(self, torrent_name: str) -> str:
        """åŸºäºè§„åˆ™çš„åˆ†ç±»"""
        # ç®€å•çš„è§„åˆ™åˆ†ç±»é€»è¾‘
        name_lower = torrent_name.lower()
        
        if any(keyword in name_lower for keyword in ['movie', 'film', 'ç”µå½±']):
            return 'movies'
        elif any(keyword in name_lower for keyword in ['tv', 'series', 'ç”µè§†']):
            return 'tv'
        elif any(keyword in name_lower for keyword in ['music', 'éŸ³ä¹']):
            return 'music'
        elif any(keyword in name_lower for keyword in ['game', 'æ¸¸æˆ']):
            return 'games'
        else:
            return 'other'
    
    async def _add_torrent_with_retry(self, magnet_link: str, category: str, save_path: str, max_retries: int = 3) -> bool:
        """å¸¦é‡è¯•æœºåˆ¶çš„ç§å­æ·»åŠ """
        for attempt in range(max_retries):
            try:
                success = await self._add_torrent_to_qb(magnet_link, category, save_path)
                if success:
                    return True
                
                if attempt < max_retries - 1:
                    wait_time = 2 ** attempt  # æŒ‡æ•°é€€é¿
                    self.logger.warning(f"æ·»åŠ å¤±è´¥ï¼Œ{wait_time}ç§’åé‡è¯• (å°è¯• {attempt + 1}/{max_retries})")
                    await asyncio.sleep(wait_time)
                    
            except Exception as e:
                if attempt < max_retries - 1:
                    wait_time = 2 ** attempt
                    self.logger.warning(f"æ·»åŠ å¼‚å¸¸: {str(e)}ï¼Œ{wait_time}ç§’åé‡è¯• (å°è¯• {attempt + 1}/{max_retries})")
                    await asyncio.sleep(wait_time)
                else:
                    self.logger.error(f"æ·»åŠ å¤±è´¥ï¼Œå·²è¾¾æœ€å¤§é‡è¯•æ¬¡æ•°: {str(e)}")
        
        return False
    
    async def _add_torrent_to_qb(self, magnet_link: str, category: str, save_path: str) -> bool:
        """æ·»åŠ ç§å­åˆ°qBittorrent"""
        try:
            return await self.qbt.add_torrent(magnet_link, category)
        except Exception as e:
            self.logger.error(f"æ·»åŠ ç§å­åˆ°qBittorrentå¤±è´¥: {str(e)}")
            return False
    
    async def _process_single_torrent_from_web(self, torrent_info, url: str, semaphore: asyncio.Semaphore) -> bool:
        """å¤„ç†ä»ç½‘é¡µæå–çš„å•ä¸ªç§å­"""
        async with semaphore:
            try:
                # æ£€æŸ¥ç£åŠ›é“¾æ¥é‡å¤
                if await self._check_duplicate_by_hash(torrent_info.get('hash', '')):
                    self.logger.info(f"è·³è¿‡é‡å¤çš„ç§å­: {torrent_info.get('name', 'Unknown')}")
                    return False
                
                # åˆ›å»ºç§å­è®°å½•
                record = TorrentRecord(
                    magnet_link=torrent_info.get('magnet_link', ''),
                    torrent_hash=torrent_info.get('hash', ''),
                    torrent_name=torrent_info.get('name', 'Unknown')
                )
                
                # åˆ†ç±»
                record.category = await self._classify_torrent_async(torrent_info.get('name', ''))
                
                # è·å–ä¿å­˜è·¯å¾„
                save_path = await self._get_save_path(record.category)
                
                # æ·»åŠ åˆ°qBittorrent
                success = await self._add_torrent_with_retry(
                    torrent_info.get('magnet_link', ''), 
                    record.category, 
                    save_path
                )
                
                if success:
                    record.status = "success"
                    self.stats['successful_adds'] += 1
                    self.logger.info(f"  âœ… {torrent_info.get('name', 'Unknown')} -> {record.category}")
                else:
                    record.status = "failed"
                    self.stats['failed_adds'] += 1
                    self.logger.error(f"  âŒ æ·»åŠ å¤±è´¥: {torrent_info.get('name', 'Unknown')}")
                
                # æ·»åŠ åˆ°å†å²è®°å½•
                self._add_to_history(record)
                return success
                
            except Exception as e:
                self.logger.error(f"å¤„ç†ç§å­æ—¶å‘ç”Ÿé”™è¯¯ {torrent_info.get('name', 'Unknown')}: {str(e)}")
                self.stats['failed_adds'] += 1
                return False
    
    async def _check_duplicate_by_hash(self, torrent_hash: str) -> bool:
        """é€šè¿‡å“ˆå¸Œæ£€æŸ¥é‡å¤"""
        if not torrent_hash:
            return False
        
        try:
            return await self.qbt._is_duplicate(torrent_hash)
        except Exception as e:
            self.logger.warning(f"æ£€æŸ¥é‡å¤å¤±è´¥: {str(e)}")
            return False
    
    def _show_farewell_message(self):
        """æ˜¾ç¤ºå‘Šåˆ«æ¶ˆæ¯"""
        if self.config.notifications.console.enabled:
            # æ˜¾ç¤ºæœ€ç»ˆç»Ÿè®¡
            if self.config.notifications.console.show_statistics:
                if self.notification_manager.use_colors:
                    from colorama import Fore, Style
                    print(f"\n{Fore.BLUE}ğŸ“Š æœ€ç»ˆç»Ÿè®¡")
                    print(f"{Fore.BLUE}{'â”€'*40}")
                    print(f"{Fore.CYAN}æ€»å¤„ç†æ•°: {Fore.WHITE}{self.stats.get('total_processed', 0)}")
                    print(f"{Fore.GREEN}æˆåŠŸæ·»åŠ : {Fore.WHITE}{self.stats.get('successful_adds', 0)}")
                    print(f"{Fore.RED}æ·»åŠ å¤±è´¥: {Fore.WHITE}{self.stats.get('failed_adds', 0)}")
                    print(f"{Fore.YELLOW}é‡å¤è·³è¿‡: {Fore.WHITE}{self.stats.get('duplicates_skipped', 0)}")
                    print(f"{Fore.MAGENTA}URLçˆ¬å–: {Fore.WHITE}{self.stats.get('url_crawls', 0)}")
                    print(f"{Fore.MAGENTA}æ‰¹é‡æ·»åŠ : {Fore.WHITE}{self.stats.get('batch_adds', 0)}")
                    print(f"{Fore.BLUE}{'â”€'*40}{Style.RESET_ALL}")
                else:
                    print(f"\nğŸ“Š æœ€ç»ˆç»Ÿè®¡")
                    print(f"{'â”€'*40}")
                    print(f"æ€»å¤„ç†æ•°: {self.stats.get('total_processed', 0)}")
                    print(f"æˆåŠŸæ·»åŠ : {self.stats.get('successful_adds', 0)}")
                    print(f"æ·»åŠ å¤±è´¥: {self.stats.get('failed_adds', 0)}")
                    print(f"é‡å¤è·³è¿‡: {self.stats.get('duplicates_skipped', 0)}")
                    print(f"URLçˆ¬å–: {self.stats.get('url_crawls', 0)}")
                    print(f"æ‰¹é‡æ·»åŠ : {self.stats.get('batch_adds', 0)}")
                    print(f"{'â”€'*40}")
            
            farewell_lines = [
                "ğŸ‘‹ qBittorrentå‰ªè´´æ¿ç›‘æ§å·²åœæ­¢",
                "æ„Ÿè°¢ä½¿ç”¨ï¼Œå†è§!"
            ]
            
            if self.notification_manager.use_colors:
                from colorama import Fore, Style
                print(f"\n{Fore.BLUE}{'='*40}")
                for line in farewell_lines:
                    print(f"{Fore.BLUE}{line}")
                print(f"{'='*40}{Style.RESET_ALL}\n")
            else:
                print(f"\n{'='*40}")
                for line in farewell_lines:
                    print(line)
                print(f"{'='*40}\n")
    
    def _add_to_history(self, record: TorrentRecord):
        """æ·»åŠ åˆ°å†å²è®°å½•"""
        try:
            self.history.append(record)
        except Exception as e:
            self.logger.warning(f"æ·»åŠ å†å²è®°å½•å¤±è´¥: {str(e)}")
    
    async def _get_save_path(self, category: str) -> str:
        """è·å–åˆ†ç±»çš„ä¿å­˜è·¯å¾„"""
        try:
            existing_categories = await self.qbt.get_existing_categories()
            if category in existing_categories:
                return existing_categories[category].get('savePath', 'é»˜è®¤è·¯å¾„')
            else:
                # ä»é…ç½®ä¸­è·å–è·¯å¾„
                if category in self.config.categories:
                    return self.config.categories[category].save_path
                    
        except Exception as e:
            self.logger.warning(f"è·å–ä¿å­˜è·¯å¾„å¤±è´¥: {str(e)}")
            
        return "é»˜è®¤è·¯å¾„"
    
    async def _periodic_stats_report(self):
        """å®šæœŸç»Ÿè®¡æŠ¥å‘Š"""
        if self.config.notifications.console.show_statistics:
            await self.notification_manager.send_statistics(self.stats)
    

    
    async def cleanup(self):
        """æ¸…ç†èµ„æº"""
        async with self._cleanup_lock:
            if self._is_cleaned_up:
                return
            
            self.logger.info("å¼€å§‹æ¸…ç†ClipboardMonitorèµ„æº...")
            self.logger.info("ğŸ” [è¯Šæ–­] ClipboardMonitorå¼€å§‹æ¸…ç†æµç¨‹...")
            
            try:
                # åœæ­¢ç›‘æ§
                self._running = False
                self.logger.info("ğŸ” [è¯Šæ–­] ç›‘æ§çŠ¶æ€å·²è®¾ç½®ä¸ºåœæ­¢")

                # åœæ­¢å·¥ä½œæµå¼•æ“
                if hasattr(self, 'workflow_engine') and self.workflow_engine:
                    self.logger.info("ğŸ” [è¯Šæ–­] åœæ­¢å·¥ä½œæµå¼•æ“...")
                    await self.workflow_engine.stop()
                    self.logger.info("âœ… [è¯Šæ–­] å·¥ä½œæµå¼•æ“å·²åœæ­¢")

                # æ¸…ç†Webçˆ¬è™«ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                if hasattr(self, 'web_crawler') and self.web_crawler:
                    self.logger.info("ğŸ” [è¯Šæ–­] æ¸…ç†Webçˆ¬è™«èµ„æº...")
                    await self.web_crawler.cleanup()
                    self.logger.info("âœ… [è¯Šæ–­] Webçˆ¬è™«èµ„æºå·²æ¸…ç†")
                
                # æ¸…ç†AIåˆ†ç±»å™¨
                if hasattr(self, 'ai_classifier') and hasattr(self.ai_classifier, 'cleanup'):
                    self.logger.info("ğŸ” [è¯Šæ–­] æ¸…ç†AIåˆ†ç±»å™¨èµ„æº...")
                    await self.ai_classifier.cleanup()
                    self.logger.info("âœ… [è¯Šæ–­] AIåˆ†ç±»å™¨èµ„æºå·²æ¸…ç†")
                
                # æ¸…ç†QBittorrentå®¢æˆ·ç«¯ï¼ˆé‡è¦ï¼è¿™å¯èƒ½æ˜¯é—æ¼çš„éƒ¨åˆ†ï¼‰
                if hasattr(self, 'qbt') and self.qbt:
                    self.logger.info("ğŸ” [è¯Šæ–­] æ¸…ç†QBittorrentå®¢æˆ·ç«¯èµ„æº...")
                    await self.qbt.cleanup()
                    self.logger.info("âœ… [è¯Šæ–­] QBittorrentå®¢æˆ·ç«¯èµ„æºå·²æ¸…ç†")
                
                # æ¸…ç†ç¼“å­˜
                if hasattr(self, '_duplicate_cache'):
                    self._duplicate_cache.clear()
                    self.logger.info("âœ… [è¯Šæ–­] é‡å¤æ£€æµ‹ç¼“å­˜å·²æ¸…ç†")
                
                # æ¸…ç†å†å²è®°å½•
                if hasattr(self, 'history'):
                    self.history.clear()
                    self.logger.info("âœ… [è¯Šæ–­] å†å²è®°å½•å·²æ¸…ç†")
                
                # ç­‰å¾…çŸ­æš‚æ—¶é—´ç¡®ä¿æ‰€æœ‰å¼‚æ­¥æ“ä½œå®Œæˆ
                self.logger.info("â³ [è¯Šæ–­] ç­‰å¾…æ‰€æœ‰å¼‚æ­¥æ“ä½œå®Œæˆ...")
                await asyncio.sleep(0.5)
                
                self._is_cleaned_up = True
                self.logger.info("âœ… [è¯Šæ–­] ClipboardMonitorèµ„æºæ¸…ç†å®Œæˆ")
                
            except Exception as e:
                self.logger.error(f"âŒ [è¯Šæ–­] æ¸…ç†ClipboardMonitorèµ„æºæ—¶å‡ºé”™: {str(e)}")
    
    def __del__(self):
        """ææ„å‡½æ•°ï¼Œç¡®ä¿èµ„æºè¢«æ¸…ç†"""
        if not self._is_cleaned_up:
            try:
                # åŒæ­¥æ¸…ç†å…³é”®èµ„æº
                if hasattr(self, '_executor') and self._executor:
                    self._executor.shutdown(wait=False)
                
                if hasattr(self, '_duplicate_cache'):
                    self._duplicate_cache.clear()
                    
                if hasattr(self, 'history'):
                    self.history.clear()
                    
            except Exception:
                pass  # å¿½ç•¥ææ„æ—¶çš„å¼‚å¸¸
    
    async def _handle_monitor_error(self, error: Exception):
        """å¤„ç†ç›‘æ§é”™è¯¯"""
        self.logger.error(f"ğŸš¨ ç›‘æ§å™¨é‡åˆ°ä¸¥é‡é”™è¯¯: {str(error)}")
        
        error_message = f"ç›‘æ§å™¨é”™è¯¯: {type(error).__name__}: {str(error)}"
        await self.notification_manager.send_torrent_failure(
            "ç³»ç»Ÿé”™è¯¯",
            error_message,
            "system_error",
            ""
        )
    
    def get_status(self) -> Dict:
        """è·å–ç›‘æ§çŠ¶æ€"""
        history_snapshot = list(self.history)
        recent_history = history_snapshot[-10:] if history_snapshot else []

        # è·å–å·¥ä½œæµå¼•æ“çŠ¶æ€
        workflow_stats = {}
        if hasattr(self, 'workflow_engine') and self.workflow_engine:
            workflow_stats = self.workflow_engine.get_stats()

        return {
            'is_running': self.is_running,
            'stats': self.stats.copy(),
            'workflow_stats': workflow_stats,
            'last_error_time': self.last_error_time.isoformat() if self.last_error_time else None,
            'consecutive_errors': self.consecutive_errors,
            'history_count': len(self.history),
            'recent_records': [
                {
                    'torrent_name': r.torrent_name,
                    'category': r.category,
                    'status': r.status,
                    'timestamp': r.timestamp.isoformat(),
                    'error_message': r.error_message,
                    'classification_method': r.classification_method,
                    'save_path': r.save_path
                }
                for r in recent_history
            ]
        }
    
    def get_history(self, limit: int = 100) -> List[Dict]:
        """è·å–å¤„ç†å†å²è®°å½•"""
        history_snapshot = list(self.history)
        recent_records = history_snapshot[-limit:] if limit > 0 else history_snapshot
        
        return [
            {
                'torrent_hash': r.torrent_hash,
                'torrent_name': r.torrent_name,
                'category': r.category,
                'status': r.status,
                'timestamp': r.timestamp.isoformat(),
                'error_message': r.error_message,
                'classification_method': r.classification_method,
                'save_path': r.save_path
            }
            for r in recent_records
        ]
    
    def clear_history(self):
        """æ¸…ç©ºå†å²è®°å½•"""
        self.history.clear()
        self.logger.info("å·²æ¸…ç©ºå†å²è®°å½•")
    
    def reset_stats(self):
        """é‡ç½®ç»Ÿè®¡ä¿¡æ¯"""
        self.stats = {
            'total_processed': 0,
            'successful_adds': 0,
            'failed_adds': 0,
            'duplicates_skipped': 0,
            'ai_classifications': 0,
            'rule_classifications': 0,
            'url_crawls': 0,
            'batch_adds': 0
        }
        self.logger.info("å·²é‡ç½®ç»Ÿè®¡ä¿¡æ¯")
    
    async def _process_url(self, url: str):
        """é«˜æ€§èƒ½å¤„ç†ç½‘é¡µURLï¼ˆæ‰¹é‡çˆ¬å–ç§å­ï¼‰"""
        process_start = time.time()
        
        self.logger.info(f"ğŸŒ æ£€æµ‹åˆ°ç½‘é¡µURL: {url}")
        
        try:
            # å¯¼å…¥web_crawleræ¨¡å—
            from .web_crawler import crawl_and_add_torrents
            
            # é€šçŸ¥å¼€å§‹æ‰¹é‡å¤„ç†
            if self.config.notifications.console.enabled:
                if self.notification_manager.use_colors:
                    from colorama import Fore, Style
                    print(f"\n{Fore.CYAN}ğŸŒ æ£€æµ‹åˆ°ç½‘é¡µURLï¼Œå¼€å§‹æ‰¹é‡æŠ“å–ç§å­...")
                    print(f"{Fore.CYAN}ğŸ“‹ URL: {url}")
                    print(f"{Fore.CYAN}ğŸ”— æ­£åœ¨åˆ†æé¡µé¢å†…å®¹...{Style.RESET_ALL}")
                else:
                    print(f"\nğŸŒ æ£€æµ‹åˆ°ç½‘é¡µURLï¼Œå¼€å§‹æ‰¹é‡æŠ“å–ç§å­...")
                    print(f"ğŸ“‹ URL: {url}")
                    print(f"ğŸ”— æ­£åœ¨åˆ†æé¡µé¢å†…å®¹...")
            
            # ä½¿ç”¨çˆ¬è™«åŠŸèƒ½æ‰¹é‡å¤„ç†ï¼ˆæ·»åŠ è¶…æ—¶æ§åˆ¶ï¼‰
            try:
                result = await asyncio.wait_for(
                    crawl_and_add_torrents(
                        url, 
                        self.config, 
                        self.qbt, 
                        max_pages=1  # é»˜è®¤åªå¤„ç†ç¬¬ä¸€é¡µï¼Œé¿å…è¿‡å¤šç§å­
                    ),
                    timeout=60.0  # 60ç§’è¶…æ—¶
                )
            except asyncio.TimeoutError:
                raise Exception("ç½‘é¡µå¤„ç†è¶…æ—¶ï¼ˆ60ç§’ï¼‰")
            
            # è®°å½•å¤„ç†æ—¶é—´
            process_time = time.time() - process_start
            self.stats['performance_metrics']['total_process_time'] += process_time
            
            if result['success']:
                # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
                stats = result['stats']['stats']
                self.stats['url_crawls'] += 1
                self.stats['total_processed'] += stats.get('torrents_found', 0)
                self.stats['successful_adds'] += stats.get('torrents_added', 0)
                self.stats['duplicates_skipped'] += stats.get('duplicates_skipped', 0)
                self.stats['failed_adds'] += stats.get('failed_adds', 0)
                
                if stats.get('torrents_added', 0) > 0:
                    self.stats['batch_adds'] += 1
                
                # æ˜¾ç¤ºæ‰¹é‡å¤„ç†ç»“æœ
                if self.config.notifications.console.enabled:
                    if self.notification_manager.use_colors:
                        from colorama import Fore, Style
                        print(f"\n{Fore.GREEN}âœ… æ‰¹é‡å¤„ç†å®Œæˆ! ({process_time:.2f}s)")
                        print(f"{Fore.CYAN}ğŸ“Š å¤„ç†ç»“æœ:")
                        print(f"   æ‰¾åˆ°ç§å­: {Fore.WHITE}{stats.get('torrents_found', 0)}")
                        print(f"   æˆåŠŸæ·»åŠ : {Fore.GREEN}{stats.get('torrents_added', 0)}")
                        print(f"   é‡å¤è·³è¿‡: {Fore.YELLOW}{stats.get('duplicates_skipped', 0)}")
                        print(f"   å¤±è´¥æ•°é‡: {Fore.RED}{stats.get('errors', 0)}")
                        print(f"{Fore.GREEN}{'â”€'*50}{Style.RESET_ALL}")
                    else:
                        print(f"\nâœ… æ‰¹é‡å¤„ç†å®Œæˆ! ({process_time:.2f}s)")
                        print(f"ğŸ“Š å¤„ç†ç»“æœ:")
                        print(f"   æ‰¾åˆ°ç§å­: {stats.get('torrents_found', 0)}")
                        print(f"   æˆåŠŸæ·»åŠ : {stats.get('torrents_added', 0)}")
                        print(f"   é‡å¤è·³è¿‡: {stats.get('duplicates_skipped', 0)}")
                        print(f"   å¤±è´¥æ•°é‡: {stats.get('errors', 0)}")
                        print(f"{'â”€'*50}")
                
                self.logger.info(f"âœ… æ‰¹é‡å¤„ç†å®Œæˆ: {result['message']} ({process_time:.2f}s)")
            else:
                self.stats['failed_adds'] += 1
                self.logger.error(f"âŒ æ‰¹é‡å¤„ç†å¤±è´¥: {result['message']} ({process_time:.2f}s)")
                
                # æ˜¾ç¤ºå¤±è´¥ä¿¡æ¯
                if self.config.notifications.console.enabled:
                    if self.notification_manager.use_colors:
                        from colorama import Fore, Style
                        print(f"\n{Fore.RED}âŒ æ‰¹é‡å¤„ç†å¤±è´¥! ({process_time:.2f}s)")
                        print(f"{Fore.CYAN}é”™è¯¯ä¿¡æ¯: {Fore.RED}{result['message']}")
                        print(f"{Fore.RED}{'â”€'*50}{Style.RESET_ALL}")
                    else:
                        print(f"\nâŒ æ‰¹é‡å¤„ç†å¤±è´¥! ({process_time:.2f}s)")
                        print(f"é”™è¯¯ä¿¡æ¯: {result['message']}")
                        print(f"{'â”€'*50}")
                
        except Exception as e:
            process_time = time.time() - process_start
            self.stats['failed_adds'] += 1
            self.logger.error(f"âŒ å¤„ç†ç½‘é¡µURLå¤±è´¥: {str(e)} ({process_time:.2f}s)")
            
            # è®°å½•é”™è¯¯ç»Ÿè®¡
            if 'errors' not in self.stats:
                self.stats['errors'] = 0
            self.stats['errors'] += 1
            
            # æ˜¾ç¤ºé”™è¯¯ä¿¡æ¯
            if self.config.notifications.console.enabled:
                if self.notification_manager.use_colors:
                    from colorama import Fore, Style
                    print(f"\n{Fore.RED}âŒ ç½‘é¡µURLå¤„ç†å¼‚å¸¸! ({process_time:.2f}s)")
                    print(f"{Fore.CYAN}é”™è¯¯è¯¦æƒ…: {Fore.RED}{str(e)}")
                    print(f"{Fore.RED}{'â”€'*50}{Style.RESET_ALL}")
                else:
                    print(f"\nâŒ ç½‘é¡µURLå¤„ç†å¼‚å¸¸! ({process_time:.2f}s)")
                    print(f"é”™è¯¯è¯¦æƒ…: {str(e)}")
                    print(f"{'â”€'*50}")


# ============================================================================
# ä¼˜åŒ–åçš„å‰ªè´´æ¿ç›‘æ§å™¨ - æ”¯æŒæ™ºèƒ½è‡ªé€‚åº”ç›‘æ§å’Œæ‰¹å¤„ç†
# ============================================================================

class ActivityTracker:
    """
    æ™ºèƒ½æ´»åŠ¨è·Ÿè¸ªå™¨ - ä¼˜åŒ–æŒ‡å¯¼æ–‡æ¡£å»ºè®®

    æ ¹æ®å‰ªè´´æ¿æ´»åŠ¨æ¨¡å¼æ™ºèƒ½è°ƒæ•´ç›‘æ§ç­–ç•¥
    """

    def __init__(self, window_size: int = 100):
        self.window_size = window_size
        self.activity_history: deque = deque(maxlen=window_size)
        self.last_activity_time = time.time()
        self.total_activities = 0
        self.current_level = 0  # 0-10 æ´»åŠ¨çº§åˆ«

    def record_activity(self, has_content: bool = False):
        """è®°å½•ä¸€æ¬¡æ´»åŠ¨"""
        current_time = time.time()
        is_active = has_content or self._is_recently_active(current_time)

        self.activity_history.append({
            'timestamp': current_time,
            'active': is_active
        })

        if is_active:
            self.last_activity_time = current_time
            self.total_activities += 1

        # è®¡ç®—å½“å‰æ´»åŠ¨çº§åˆ«
        self._calculate_activity_level()

    def _is_recently_active(self, current_time: float, threshold: float = 5.0) -> bool:
        """æ£€æŸ¥æœ€è¿‘æ˜¯å¦æ´»è·ƒ"""
        return (current_time - self.last_activity_time) < threshold

    def _calculate_activity_level(self):
        """è®¡ç®—å½“å‰æ´»åŠ¨çº§åˆ« (0-10)"""
        if not self.activity_history:
            self.current_level = 0
            return

        # è®¡ç®—æœ€è¿‘1åˆ†é’Ÿçš„æ´»åŠ¨ç‡
        current_time = time.time()
        recent_window = 60  # 1åˆ†é’Ÿ
        active_count = 0
        total_count = 0

        for entry in reversed(self.activity_history):
            if current_time - entry['timestamp'] > recent_window:
                break
            total_count += 1
            if entry['active']:
                active_count += 1

        # è®¡ç®—æ´»åŠ¨çº§åˆ«
        if total_count == 0:
            self.current_level = 0
        else:
            activity_rate = active_count / total_count
            self.current_level = min(10, int(activity_rate * 10))

    async def get_level(self) -> int:
        """è·å–å½“å‰æ´»åŠ¨çº§åˆ« (0-10)"""
        return self.current_level

    def get_stats(self) -> Dict:
        """è·å–æ´»åŠ¨ç»Ÿè®¡"""
        return {
            'total_activities': self.total_activities,
            'current_level': self.current_level,
            'window_size': len(self.activity_history),
            'is_active': self._is_recently_active(time.time())
        }


class SmartBatcher:
    """
    æ™ºèƒ½æ‰¹å¤„ç†å™¨ - ä¼˜åŒ–æŒ‡å¯¼æ–‡æ¡£å»ºè®®

    æ ¹æ®å†…å®¹ç±»å‹å’Œç³»ç»Ÿè´Ÿè½½æ™ºèƒ½è°ƒæ•´æ‰¹å¤„ç†ç­–ç•¥
    """

    def __init__(self, max_size: int = 10, timeout: float = 0.5):
        self.max_size = max_size
        self.timeout = timeout
        self.batch_queue = asyncio.Queue(maxsize=100)
        self.processor: Optional[any] = None  # ç±»å‹ä¼šåœ¨è¿è¡Œæ—¶è®¾ç½®
        self.stats = {
            'batches_processed': 0,
            'items_processed': 0,
            'avg_batch_size': 0.0,
            'queue_pressure': 0.0
        }

    def set_processor(self, processor):
        """è®¾ç½®æ‰¹å¤„ç†å™¨"""
        self.processor = processor

    async def add_to_batch(self, item: Dict):
        """æ·»åŠ é¡¹ç›®åˆ°æ‰¹æ¬¡"""
        try:
            # éé˜»å¡å¼æ·»åŠ 
            self.batch_queue.put_nowait(item)
        except asyncio.QueueFull:
            # é˜Ÿåˆ—æ»¡æ—¶ï¼Œç«‹å³å¤„ç†å½“å‰æ‰¹æ¬¡
            self.logger.warning("æ‰¹æ¬¡é˜Ÿåˆ—å·²æ»¡ï¼Œç«‹å³å¤„ç†å½“å‰æ‰¹æ¬¡")
            await self._process_batch()

        # åŠ¨æ€è°ƒæ•´æ‰¹æ¬¡å¤§å°
        await self._adjust_batch_size()

    async def _process_batch(self):
        """å¤„ç†å½“å‰æ‰¹æ¬¡"""
        if self.processor is None:
            self.logger.error("æ‰¹å¤„ç†å™¨æœªè®¾ç½®")
            return

        items = []
        batch_start_time = time.time()

        # æ”¶é›†æ‰¹æ¬¡é¡¹ç›®
        try:
            # ç«‹å³è·å–ç¬¬ä¸€ä¸ªé¡¹ç›®
            first_item = await asyncio.wait_for(self.batch_queue.get(), timeout=0.1)
            items.append(first_item)

            # å°è¯•è·å–æ›´å¤šé¡¹ç›® (ç›´åˆ°è¾¾åˆ°æ‰¹æ¬¡å¤§å°æˆ–è¶…æ—¶)
            while len(items) < self.max_size:
                try:
                    item = await asyncio.wait_for(
                        self.batch_queue.get(),
                        timeout=self.timeout
                    )
                    items.append(item)
                except asyncio.TimeoutError:
                    break

        except Exception as e:
            self.logger.error(f"æ”¶é›†æ‰¹æ¬¡é¡¹ç›®æ—¶å‡ºé”™: {str(e)}")
            return

        if not items:
            return

        # è®°å½•ç»Ÿè®¡
        self.stats['batches_processed'] += 1
        self.stats['items_processed'] += len(items)

        # è®¡ç®—å¹³å‡æ‰¹æ¬¡å¤§å°
        total_items = self.stats['items_processed']
        total_batches = self.stats['batches_processed']
        self.stats['avg_batch_size'] = total_items / total_batches

        # å¤„ç†æ‰¹æ¬¡
        try:
            await self.processor.process_batch(items, batch_start_time)
            self.logger.debug(
                f"æ‰¹æ¬¡å¤„ç†å®Œæˆ: {len(items)} ä¸ªé¡¹ç›® "
                f"(ç”¨æ—¶: {time.time() - batch_start_time:.3f}s)"
            )
        except Exception as e:
            self.logger.error(f"æ‰¹æ¬¡å¤„ç†å¤±è´¥: {str(e)}")

    async def _adjust_batch_size(self):
        """åŠ¨æ€è°ƒæ•´æ‰¹æ¬¡å¤§å°"""
        current_size = self.batch_queue.qsize()
        queue_pressure = current_size / self.batch_queue.maxsize

        # è®°å½•é˜Ÿåˆ—å‹åŠ›
        self.stats['queue_pressure'] = queue_pressure

        # æ ¹æ®é˜Ÿåˆ—å‹åŠ›è°ƒæ•´æ‰¹æ¬¡å¤§å°
        if queue_pressure > 0.8:
            # é«˜å‹åŠ›ï¼šå¢åŠ æ‰¹æ¬¡å¤§å°ä»¥æé«˜ååé‡
            self.max_size = min(20, self.max_size + 1)
        elif queue_pressure < 0.2:
            # ä½å‹åŠ›ï¼šå‡å°‘æ‰¹æ¬¡å¤§å°ä»¥æé«˜å“åº”é€Ÿåº¦
            self.max_size = max(5, self.max_size - 1)

    def get_stats(self) -> Dict:
        """è·å–æ‰¹å¤„ç†ç»Ÿè®¡"""
        return {
            **self.stats,
            'current_queue_size': self.batch_queue.qsize(),
            'current_batch_size': self.max_size,
            'timeout': self.timeout
        }


class OptimizedClipboardMonitor(ClipboardMonitor):
    """
    ä¼˜åŒ–ç‰ˆå‰ªè´´æ¿ç›‘æ§å™¨ - ç»§æ‰¿è‡ªåŸç›‘æ§å™¨

    æ–°å¢åŠŸèƒ½:
    1. æ™ºèƒ½è‡ªé€‚åº”ç›‘æ§ (ActivityTracker)
    2. æ™ºèƒ½æ‰¹å¤„ç† (SmartBatcher)
    3. åŠ¨æ€æ€§èƒ½è°ƒä¼˜
    4. é«˜çº§ç»Ÿè®¡
    """

    def __init__(self, qbt: QBittorrentClient, config: AppConfig):
        super().__init__(qbt, config)
        self.logger = logging.getLogger('OptimizedClipboardMonitor')

        # åˆå§‹åŒ–æ™ºèƒ½æ´»åŠ¨è·Ÿè¸ªå™¨
        self.activity_tracker = ActivityTracker(window_size=100)

        # åˆå§‹åŒ–æ™ºèƒ½æ‰¹å¤„ç†å™¨
        self.smart_batcher = SmartBatcher(
            max_size=getattr(config, 'batch_size', 10),
            timeout=getattr(config, 'batch_timeout', 0.5)
        )
        self.smart_batcher.set_processor(self)

        # é«˜çº§æ€§èƒ½ç»Ÿè®¡
        self.advanced_stats = {
            'activity_levels': deque(maxlen=100),
            'batch_sizes': deque(maxlen=100),
            'processing_latency': deque(maxlen=100),
            'adaptive_adjustments': 0,
            'cpu_saved_percent': 0.0
        }

    async def _on_clipboard_change_optimized(self, text: str):
        """ä¼˜åŒ–çš„å‰ªè´´æ¿å˜åŒ–å¤„ç†"""
        # è®°å½•æ´»åŠ¨
        has_content = bool(text and text.strip())
        self.activity_tracker.record_activity(has_content)

        # åŠ¨æ€è°ƒæ•´è½®è¯¢é—´éš”
        await self._adjust_monitoring_interval()

        # æ™ºèƒ½æ‰¹å¤„ç†
        if has_content:
            content_item = {
                'text': text,
                'timestamp': time.time(),
                'source': 'clipboard'
            }
            await self.smart_batcher.add_to_batch(content_item)

    async def _adjust_monitoring_interval(self):
        """æ ¹æ®æ´»åŠ¨çº§åˆ«åŠ¨æ€è°ƒæ•´ç›‘æ§é—´éš”"""
        activity_level = await self.activity_tracker.get_level()

        # è®¡ç®—ç›®æ ‡é—´éš”
        if activity_level >= 8:
            # é«˜æ´»è·ƒåº¦ï¼šä½¿ç”¨æœ€å°é—´éš”
            target_interval = self._max_interval * 0.1
        elif activity_level >= 5:
            # ä¸­ç­‰æ´»è·ƒåº¦ï¼šä½¿ç”¨åŸºç¡€é—´éš”
            target_interval = self._base_interval
        elif activity_level >= 2:
            # ä½æ´»è·ƒåº¦ï¼šå¢åŠ é—´éš”
            target_interval = self._base_interval * 2
        else:
            # æ— æ´»è·ƒï¼šä½¿ç”¨æœ€å¤§é—´éš”
            target_interval = self._max_interval

        # å¹³æ»‘è°ƒæ•´é—´éš”
        if hasattr(self.poller, 'current_interval'):
            current = self.poller.current_interval
            # ä½¿ç”¨æŒ‡æ•°ç§»åŠ¨å¹³å‡è¿›è¡Œå¹³æ»‘è°ƒæ•´
            smooth_factor = 0.1
            new_interval = current * (1 - smooth_factor) + target_interval * smooth_factor

            # é™åˆ¶åœ¨åˆç†èŒƒå›´å†…
            new_interval = max(
                self.poller.config.min_interval,
                min(new_interval, self.poller.config.max_interval)
            )

            if abs(new_interval - current) > 0.01:  # åªæœ‰å˜åŒ–æ˜¾è‘—æ—¶æ‰è°ƒæ•´
                self.poller.current_interval = new_interval
                self.advanced_stats['adaptive_adjustments'] += 1

        # è®°å½•æ´»åŠ¨çº§åˆ«
        self.advanced_stats['activity_levels'].append(activity_level)

    async def process_batch(self, items: List[Dict], batch_start_time: float):
        """å¤„ç†æ‰¹æ¬¡å†…å®¹"""
        if not items:
            return

        start_time = batch_start_time or time.time()
        results = {
            'total': len(items),
            'successful': 0,
            'failed': 0,
            'duplicates': 0
        }

        # å¹¶å‘å¤„ç†æ‰¹æ¬¡ä¸­çš„æ‰€æœ‰é¡¹ç›®
        tasks = []
        for item in items:
            task = asyncio.create_task(self._process_single_item(item))
            tasks.append(task)

        # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
        batch_results = await asyncio.gather(*tasks, return_exceptions=True)

        # ç»Ÿè®¡ç»“æœ
        for result in batch_results:
            if isinstance(result, Exception):
                results['failed'] += 1
                self.logger.error(f"æ‰¹æ¬¡é¡¹ç›®å¤„ç†å¤±è´¥: {str(result)}")
            elif result == 'duplicate':
                results['duplicates'] += 1
            elif result == 'success':
                results['successful'] += 1

        # æ›´æ–°ç»Ÿè®¡
        batch_size = len(items)
        self.advanced_stats['batch_sizes'].append(batch_size)
        self.advanced_stats['processing_latency'].append(time.time() - start_time)

        self.logger.info(
            f"æ‰¹æ¬¡å¤„ç†å®Œæˆ: {results['successful']}/{results['total']} æˆåŠŸ, "
            f"{results['duplicates']} é‡å¤, {results['failed']} å¤±è´¥ "
            f"(ç”¨æ—¶: {time.time() - start_time:.3f}s)"
        )

        # è®¡ç®—CPUèŠ‚çœ
        await self._calculate_cpu_savings()

    async def _process_single_item(self, item: Dict) -> str:
        """å¤„ç†å•ä¸ªé¡¹ç›®"""
        try:
            text = item.get('text', '')
            if not text:
                return 'failed'

            # è°ƒç”¨åŸæœ‰çš„å¤„ç†é€»è¾‘
            await self._on_clipboard_change(text)
            return 'success'
        except Exception as e:
            self.logger.error(f"å¤„ç†é¡¹ç›®æ—¶å‡ºé”™: {str(e)}")
            return 'failed'

    async def _calculate_cpu_savings(self):
        """è®¡ç®—CPUä½¿ç”¨èŠ‚çœ"""
        # åŸºäºè‡ªé€‚åº”é—´éš”è®¡ç®—CPUèŠ‚çœ
        if self.advanced_stats['activity_levels']:
            recent_levels = list(self.advanced_stats['activity_levels'])[-10:]
            avg_level = sum(recent_levels) / len(recent_levels)

            # ä¼°ç®—CPUèŠ‚çœç™¾åˆ†æ¯”
            if avg_level < 3:
                # ä½æ´»è·ƒåº¦ï¼šèŠ‚çœæ›´å¤šCPU
                cpu_saved = 70
            elif avg_level < 6:
                # ä¸­ç­‰æ´»è·ƒåº¦ï¼šèŠ‚çœä¸€äº›CPU
                cpu_saved = 40
            else:
                # é«˜æ´»è·ƒåº¦ï¼šèŠ‚çœå°‘é‡CPU
                cpu_saved = 10

            # å¹³æ»‘æ›´æ–°
            current_saved = self.advanced_stats['cpu_saved_percent']
            self.advanced_stats['cpu_saved_percent'] = current_saved * 0.9 + cpu_saved * 0.1

    def get_advanced_stats(self) -> Dict:
        """è·å–é«˜çº§ç»Ÿè®¡ä¿¡æ¯"""
        stats = self.advanced_stats.copy()

        # è®¡ç®—å¹³å‡å€¼
        if self.advanced_stats['activity_levels']:
            stats['avg_activity_level'] = sum(self.advanced_stats['activity_levels']) / len(
                self.advanced_stats['activity_levels']
            )
        else:
            stats['avg_activity_level'] = 0

        if self.advanced_stats['batch_sizes']:
            stats['avg_batch_size'] = sum(self.advanced_stats['batch_sizes']) / len(
                self.advanced_stats['batch_sizes']
            )
        else:
            stats['avg_batch_size'] = 0

        if self.advanced_stats['processing_latency']:
            stats['avg_processing_latency'] = sum(
                self.advanced_stats['processing_latency']
            ) / len(self.advanced_stats['processing_latency'])
        else:
            stats['avg_processing_latency'] = 0

        # æ·»åŠ æ™ºèƒ½æ‰¹å¤„ç†å™¨ç»Ÿè®¡
        stats['smart_batcher'] = self.smart_batcher.get_stats()

        # æ·»åŠ æ´»åŠ¨è·Ÿè¸ªå™¨ç»Ÿè®¡
        stats['activity_tracker'] = self.activity_tracker.get_stats()

        return stats

    async def start(self):
        """å¯åŠ¨ä¼˜åŒ–ç‰ˆç›‘æ§å™¨"""
        self.logger.info("ğŸš€ å¯åŠ¨ä¼˜åŒ–ç‰ˆå‰ªè´´æ¿ç›‘æ§å™¨ (æ™ºèƒ½è‡ªé€‚åº” + æ‰¹å¤„ç†)")

        # è®°å½•å¯åŠ¨æ—¶é—´
        self.start_time = time.time()

        # è¦†ç›–åŸæœ‰çš„å˜åŒ–å¤„ç†æ–¹æ³•
        original_on_change = self._on_clipboard_change
        self._on_clipboard_change = self._on_clipboard_change_optimized

        try:
            # å¯åŠ¨çˆ¶ç±»ç›‘æ§
            await super().start()
        finally:
            # æ¢å¤åŸæœ‰æ–¹æ³•
            self._on_clipboard_change = original_on_change
